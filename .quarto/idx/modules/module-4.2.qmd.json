{"title":"Module 4.2","markdown":{"yaml":{"title":"Module 4.2","subtitle":"Hypothesis Testing 2","format":{"html":{"code-link":true}},"highlight-style":"atom-one","execute":{"echo":true,"message":false,"warning":false}},"headingText":"Prework","containsRefs":false,"markdown":"\n\n::: {.callout-tip}\n\n- Read Chapter 20 of [IMS](https://openintro-ims.netlify.app/)\n:::\n\n## Overview\n\nIn the previous module, we learned about hypothesis testing and how to test hypotheses about a single mean. In this module, we will learn how to test hypotheses about two means. We will learn about treatment effects, which are the differences in means between two groups. We will learn how to permute our data to simulate a null distribution of treatment effects and compare this with the observed treatment effect to test the null hypothesis. And we will apply these skills to a real-world example from the field of international development.\n\nIn this lesson, we are going to be furthering our understanding of **non-parametric methods** for hypothesis testing. Recall that non-parametric methods are used when assumptions of normality are not met or when the shape of the distribution is unknown, as is often the case in social science analysis. \n\nFor the case of comparing two means, we will be using a **permutation test**. A permutation test generates a null distribution of the test statistic by shuffling the data many times and recalculating the test statistic each time. This allows us to test hypotheses about the mean without making assumptions about the distribution of the data. Here is a video that gives the intuition behind permutation tests:\n\n{{< video https://youtu.be/rJ3AZCQuiLw?si=ouSZSRXxn-OD9isj title='Permutation Hypothesis Tests with Example' >}}\n\n## Comparing two means\n\nOften in the social sciences, we are interested in comparing two groups. This situation is especially common in experimental studies, where we are interested in comparing the outcomes of a treatment group to a control group. \n\nExperimental studies, as you may know, are very important in the realm of international development. Monitoring and evaluation of development projects often involve comparing the outcomes groups that were exposed to a program and those that were not. \n\nIn such scenarious, our null hypothesis is that there is no difference between the two groups while the alternative hypothesis is that there is a difference between the two groups. Under the null hypothesis, treatment has **NO** impact on the outcome of interest. This means that if we were to change the values of the treatment variable, the values of the outcome would stay the same. \n\nOur strategy for testing the null hypothesis is to calculate the difference in means between the two groups and then compare this difference to the distribution of differences that we would expect to see if the null hypothesis were true. To do this, we can simulate the null distribution by reshuffling the treatment variable, calculating the treatment effect and then repeating this process many times. Then we can ask: how likely would we be to observe the treatment effect in our data, *if there is no effect of the treatment*?\n\nLet's assume that we are interested in the impact of a program on the income of participants. We have data on the income of participants in the treatment group and the control group that looks like this:\n \n| Village | Program | Outcome  |\n|---------|---------|----------|\n| A       | Yes     | Yes      |\n| B       | Yes     | No       |\n| C       | Yes     | No       |\n| D       | No      | Yes      |\n| E       | No      | No       |\n| F       | No      | No       |\n\nOur first step would be to calculate the difference in means between the two groups for the outcome in question. The objective would be to understand the initial observed association between participation in the program and the outcome of interest.\n\nNext, we would shuffle the treatment variable (program participation), but not the outcome, and recalculate the difference in means, like this:\n\n| Village | Program | Outcome  |\n|---------|---------|----------|\n| A       | Yes     | Yes      |\n| B       | No      | No       |\n| C       | Yes     | No       |\n| D       | Yes     | Yes      |\n| E       | No      | No       |\n| F       | No      | No       |\n\nAnd then again take the difference in means between the two groups. \n\nWe would repeat this process many times to generate a distribution of differences in means that we would expect to see if the null hypothesis were true. In doing this, we are essentially asking \"what would the distribution of differences in means look like if the relationship between the treatment and outcome were completely random?\"\n\nFinally, we would compare the observed difference in means to the distribution of differences in means that we generated through our random shuffling (our bootstrap procedure). If the observed difference in means is extreme (i.e. it is very unlikely to have occurred by chance), we would reject the null hypothesis and conclude that the treatment has an impact on the outcome of interest.\n\n## Post-conflict development example\n\nSierra Leone was devastated by a [civil war](http://web.undp.org/evaluation/documents/thematic/conflict/SierraLeone.pdf) lasting from 1991 to 2002. In the post-conflict context, the Ministry of Local Government and Community Development implemented the GoBifo (\"forge ahead\") CDD project in Sierra Leone from 2005-2009 (with support from the World Bank and other international donors). See this [report](https://thedocs.worldbank.org/en/doc/6f445967d38ba97805febe703b2482ef-0060052022/original/Sierra-Leone-GoBifo-Strengthening-Social-Capital-through-Capacity-Development.pdf) for a detailed summary of the program.\n\nThe GiBifo program also included an impact evaluation, conducted by economists Katherine Casey, Rachel Glennerster, and Edward Miguel. The original study includes dozens of outcome variables, but for the purposes of this illustration we will focus on just the treatment variable and whether the community had a village development committee (VDC) which is coded \"1\" if the village had one and \"0\" if it did not. \n\nIn other words, we will be looking at whether participation in the program boosts the chance that a village has a VDC. You can access the data for this exercise [here]() or in the classwork folder. \n\nLet's start by loading the packages and have a `glimpse()` at the data.\n\n```{r}\n#| label: setup\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\ngobifo_data <- read_csv(\"data/gobifo_data.csv\")\n\nglimpse(gobifo_data)\n```\n\nThere are 236 villages in the study and eight columns in the data frame. There is a village ID, a variable that distinguishes between treatmetn and control groups, and five outcome variables. As mentioned, we will just be focusing on the treatment variable and the village decision making infrastructure (vdc) variable here. \n\nLet's count the observations in the treatment and control groups.\n\n```{r}\n#| label: treatment-control\n\ngobifo_data |>\n  group_by(t) |>\n  count()\n```\n\nIt looks like the villages are evenly split: 118 in the treatment group and 118 in the control group.\n\nNext, let's calculate the means of the VDC variable in the treatment and control groups and also calculate the **treatment effect**. The treatment effect is the difference in means between the treatment and control groups.\n\n```{r}\n#| label: means\n\n# calculate the means of each response variable in both treatment and control villages\nmeans <- gobifo_data |>\n  group_by(t) |>\n  summarize(mean_vdc = mean(vdc, na.rm = TRUE))\n\n# store the means for treatment and control as separate objects\nmean_vdc_t <- means$mean_vdc[2]\nmean_vdc_c <- means$mean_vdc[1]\n\n# calculate the treatment effect and store\nteffect_vdc <- mean_vdc_t - mean_vdc_c\n\n# print the results\nteffect_vdc\n```\n\nWe see that the treatment effect is 0.406. This means that the villages in the treatment group are about 40.6% more likely to have a VDC than the villages in the control group.\n\nNow we can get about the business of testing our hypothesis that the program had an impact on the presence of VDCs in the villages. Our null and alternative hypotheses are as follows:\n\n**Null Hypothesis:** The mean of VDCs in the treatment group is equal to the mean of VDCs in the control group. Or, in other words, the program had no impact on VDCs.\n\n**Alternative Hypothesis:** The mean of VDCs in the treatment group is not equal to the mean of VDCs in the control group. Or, in other words, the program had an impact on VDCs.\n\nNow we can use the `infer` package to conduct a hypothesis test. First we specify the response variable, which in this case is the VDC variable, and the explanatory variable, which is the treatment variable. Then we hypothesize that the two variables are independent of each other. Next, we generate a null distribution by permuting the treatment variable and calculating the difference in means between the treatment and control groups. Finally, we calculate the p-value by comparing the observed treatment effect to the null distribution.\n\n```{r}\n#| label: hypothesis_test_vdc\n\nnull_dist_vdc <- gobifo_data |> \n  specify(response = vdc, explanatory = t) |>\n  hypothesize(null = \"independence\") |> \n  generate(reps = 10000, type = \"permute\") |> \n  calculate(stat = \"diff in means\",\n            order = c(\"control\", \"treatment\"))\n\n# calculate p-value using infer\nget_pvalue(null_dist_vdc, obs_stat = teffect_vdc, direction = \"greater\")\n```\n\nRemember that the null distribution is the distribution of treatment effects we would expect to see if the program had no impact. The treatment effect is the difference in means we observed in the data. If the treatment effect is far from the null distribution, it suggests that the treatment effect is unlikely to be due to chance alone.\n\nIn this case, we see that our p-value is zero, meaning that there are no treatment effects in the null distribution that are as extreme as the treatment effect we observed. This means that the treatment effect is very unlikely to be due to chance alone and we can reject the null hypothesis.\n\nFinally, let's visualize the treatment effect relative to the null distribution using the `visualize()` function from the `infer` package.\n\n```{r}\nvisualize(null_dist_vdc) +\n  shade_p_value(obs_stat = teffect_vdc, direction = \"greater\") +\n  labs(title = \"Null Distribution for VDC\",\n    x = \"Estimated Difference under the Null\", \n    y = \"Count\") +\n  theme_bw()\n```\n\nHere we can see just how far the treatment effect is from the null distribution. There are no observations in the null distribution that are as extreme as the treatment effect we observed, and this is why we get a p-value of 0. This is pretty strong evidence that the program has an impact on the presence of VDCs in the villages.\n\n","srcMarkdownNoYaml":"\n\n::: {.callout-tip}\n## Prework\n\n- Read Chapter 20 of [IMS](https://openintro-ims.netlify.app/)\n:::\n\n## Overview\n\nIn the previous module, we learned about hypothesis testing and how to test hypotheses about a single mean. In this module, we will learn how to test hypotheses about two means. We will learn about treatment effects, which are the differences in means between two groups. We will learn how to permute our data to simulate a null distribution of treatment effects and compare this with the observed treatment effect to test the null hypothesis. And we will apply these skills to a real-world example from the field of international development.\n\nIn this lesson, we are going to be furthering our understanding of **non-parametric methods** for hypothesis testing. Recall that non-parametric methods are used when assumptions of normality are not met or when the shape of the distribution is unknown, as is often the case in social science analysis. \n\nFor the case of comparing two means, we will be using a **permutation test**. A permutation test generates a null distribution of the test statistic by shuffling the data many times and recalculating the test statistic each time. This allows us to test hypotheses about the mean without making assumptions about the distribution of the data. Here is a video that gives the intuition behind permutation tests:\n\n{{< video https://youtu.be/rJ3AZCQuiLw?si=ouSZSRXxn-OD9isj title='Permutation Hypothesis Tests with Example' >}}\n\n## Comparing two means\n\nOften in the social sciences, we are interested in comparing two groups. This situation is especially common in experimental studies, where we are interested in comparing the outcomes of a treatment group to a control group. \n\nExperimental studies, as you may know, are very important in the realm of international development. Monitoring and evaluation of development projects often involve comparing the outcomes groups that were exposed to a program and those that were not. \n\nIn such scenarious, our null hypothesis is that there is no difference between the two groups while the alternative hypothesis is that there is a difference between the two groups. Under the null hypothesis, treatment has **NO** impact on the outcome of interest. This means that if we were to change the values of the treatment variable, the values of the outcome would stay the same. \n\nOur strategy for testing the null hypothesis is to calculate the difference in means between the two groups and then compare this difference to the distribution of differences that we would expect to see if the null hypothesis were true. To do this, we can simulate the null distribution by reshuffling the treatment variable, calculating the treatment effect and then repeating this process many times. Then we can ask: how likely would we be to observe the treatment effect in our data, *if there is no effect of the treatment*?\n\nLet's assume that we are interested in the impact of a program on the income of participants. We have data on the income of participants in the treatment group and the control group that looks like this:\n \n| Village | Program | Outcome  |\n|---------|---------|----------|\n| A       | Yes     | Yes      |\n| B       | Yes     | No       |\n| C       | Yes     | No       |\n| D       | No      | Yes      |\n| E       | No      | No       |\n| F       | No      | No       |\n\nOur first step would be to calculate the difference in means between the two groups for the outcome in question. The objective would be to understand the initial observed association between participation in the program and the outcome of interest.\n\nNext, we would shuffle the treatment variable (program participation), but not the outcome, and recalculate the difference in means, like this:\n\n| Village | Program | Outcome  |\n|---------|---------|----------|\n| A       | Yes     | Yes      |\n| B       | No      | No       |\n| C       | Yes     | No       |\n| D       | Yes     | Yes      |\n| E       | No      | No       |\n| F       | No      | No       |\n\nAnd then again take the difference in means between the two groups. \n\nWe would repeat this process many times to generate a distribution of differences in means that we would expect to see if the null hypothesis were true. In doing this, we are essentially asking \"what would the distribution of differences in means look like if the relationship between the treatment and outcome were completely random?\"\n\nFinally, we would compare the observed difference in means to the distribution of differences in means that we generated through our random shuffling (our bootstrap procedure). If the observed difference in means is extreme (i.e. it is very unlikely to have occurred by chance), we would reject the null hypothesis and conclude that the treatment has an impact on the outcome of interest.\n\n## Post-conflict development example\n\nSierra Leone was devastated by a [civil war](http://web.undp.org/evaluation/documents/thematic/conflict/SierraLeone.pdf) lasting from 1991 to 2002. In the post-conflict context, the Ministry of Local Government and Community Development implemented the GoBifo (\"forge ahead\") CDD project in Sierra Leone from 2005-2009 (with support from the World Bank and other international donors). See this [report](https://thedocs.worldbank.org/en/doc/6f445967d38ba97805febe703b2482ef-0060052022/original/Sierra-Leone-GoBifo-Strengthening-Social-Capital-through-Capacity-Development.pdf) for a detailed summary of the program.\n\nThe GiBifo program also included an impact evaluation, conducted by economists Katherine Casey, Rachel Glennerster, and Edward Miguel. The original study includes dozens of outcome variables, but for the purposes of this illustration we will focus on just the treatment variable and whether the community had a village development committee (VDC) which is coded \"1\" if the village had one and \"0\" if it did not. \n\nIn other words, we will be looking at whether participation in the program boosts the chance that a village has a VDC. You can access the data for this exercise [here]() or in the classwork folder. \n\nLet's start by loading the packages and have a `glimpse()` at the data.\n\n```{r}\n#| label: setup\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\ngobifo_data <- read_csv(\"data/gobifo_data.csv\")\n\nglimpse(gobifo_data)\n```\n\nThere are 236 villages in the study and eight columns in the data frame. There is a village ID, a variable that distinguishes between treatmetn and control groups, and five outcome variables. As mentioned, we will just be focusing on the treatment variable and the village decision making infrastructure (vdc) variable here. \n\nLet's count the observations in the treatment and control groups.\n\n```{r}\n#| label: treatment-control\n\ngobifo_data |>\n  group_by(t) |>\n  count()\n```\n\nIt looks like the villages are evenly split: 118 in the treatment group and 118 in the control group.\n\nNext, let's calculate the means of the VDC variable in the treatment and control groups and also calculate the **treatment effect**. The treatment effect is the difference in means between the treatment and control groups.\n\n```{r}\n#| label: means\n\n# calculate the means of each response variable in both treatment and control villages\nmeans <- gobifo_data |>\n  group_by(t) |>\n  summarize(mean_vdc = mean(vdc, na.rm = TRUE))\n\n# store the means for treatment and control as separate objects\nmean_vdc_t <- means$mean_vdc[2]\nmean_vdc_c <- means$mean_vdc[1]\n\n# calculate the treatment effect and store\nteffect_vdc <- mean_vdc_t - mean_vdc_c\n\n# print the results\nteffect_vdc\n```\n\nWe see that the treatment effect is 0.406. This means that the villages in the treatment group are about 40.6% more likely to have a VDC than the villages in the control group.\n\nNow we can get about the business of testing our hypothesis that the program had an impact on the presence of VDCs in the villages. Our null and alternative hypotheses are as follows:\n\n**Null Hypothesis:** The mean of VDCs in the treatment group is equal to the mean of VDCs in the control group. Or, in other words, the program had no impact on VDCs.\n\n**Alternative Hypothesis:** The mean of VDCs in the treatment group is not equal to the mean of VDCs in the control group. Or, in other words, the program had an impact on VDCs.\n\nNow we can use the `infer` package to conduct a hypothesis test. First we specify the response variable, which in this case is the VDC variable, and the explanatory variable, which is the treatment variable. Then we hypothesize that the two variables are independent of each other. Next, we generate a null distribution by permuting the treatment variable and calculating the difference in means between the treatment and control groups. Finally, we calculate the p-value by comparing the observed treatment effect to the null distribution.\n\n```{r}\n#| label: hypothesis_test_vdc\n\nnull_dist_vdc <- gobifo_data |> \n  specify(response = vdc, explanatory = t) |>\n  hypothesize(null = \"independence\") |> \n  generate(reps = 10000, type = \"permute\") |> \n  calculate(stat = \"diff in means\",\n            order = c(\"control\", \"treatment\"))\n\n# calculate p-value using infer\nget_pvalue(null_dist_vdc, obs_stat = teffect_vdc, direction = \"greater\")\n```\n\nRemember that the null distribution is the distribution of treatment effects we would expect to see if the program had no impact. The treatment effect is the difference in means we observed in the data. If the treatment effect is far from the null distribution, it suggests that the treatment effect is unlikely to be due to chance alone.\n\nIn this case, we see that our p-value is zero, meaning that there are no treatment effects in the null distribution that are as extreme as the treatment effect we observed. This means that the treatment effect is very unlikely to be due to chance alone and we can reject the null hypothesis.\n\nFinally, let's visualize the treatment effect relative to the null distribution using the `visualize()` function from the `infer` package.\n\n```{r}\nvisualize(null_dist_vdc) +\n  shade_p_value(obs_stat = teffect_vdc, direction = \"greater\") +\n  labs(title = \"Null Distribution for VDC\",\n    x = \"Estimated Difference under the Null\", \n    y = \"Count\") +\n  theme_bw()\n```\n\nHere we can see just how far the treatment effect is from the null distribution. There are no observations in the null distribution that are as extreme as the treatment effect we observed, and this is why we get a p-value of 0. This is pretty strong evidence that the program has an impact on the presence of VDCs in the villages.\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"wrap","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"highlight-style":"atom-one","output-file":"module-4.2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.533","editor":"source","theme":{"light":"cosmo","dark":"cyborg"},"mainfont":"Atkinson Hyperlegible","code-copy":true,"title":"Module 4.2","subtitle":"Hypothesis Testing 2"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}