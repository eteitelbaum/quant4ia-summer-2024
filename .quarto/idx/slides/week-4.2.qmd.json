{"title":"Hypothesis Testing","markdown":{"yaml":{"title":"Hypothesis Testing","date":"today","date-format":"long","footer":"[IAFF 6501 Website](https://quant4ia.rocks/)","logo":"images/iaff6501-logo.png","format":{"revealjs":{"theme":["simple","custom.scss"],"transition":"fade","slide-number":true,"chalkboard":true}},"execute":{"echo":false,"message":false,"warning":false,"freeze":"auto"}},"headingText":"Hypothesis Test for a Single Proportion","containsRefs":false,"markdown":"\n\n\n## Jobs Training Programs\n\n-   International development organizations are sometimes interested in providing training to people in order to help them find a job\n-   Imagine the unemployment rate in a low-income country is 30%\n-   One organization claims that its jobs training program is a success because only 15 of the 60 people that they trained did not have a job (25% unemployment rate)\n-   What should we think about this claim? Is this a successful program?\n\n## Today's Code\n\n<https://www.dropbox.com/scl/fo/g4tdpdwcij78nyydvr4bp/h?rlkey=hctskhle6222csnwre5ir9gz3&dl=0>\n\n## \n\n<br>\n\nNow let's create some data to match our hypothetical example.\n\n<br>\n\n```{r}\n#| echo: true\n\nlibrary(tidyverse)\n\njobs_program <- tibble(\n  outcome = c(rep(\"unemployed\", 15), rep(\"employed\", 45))\n)\n\n```\n\n## \n\n<br>\n\nUse the base R `head()` function to see the first five rows.\n\n```{r}\n#| echo: true\n\nhead(jobs_program)\n```\n\n## \n\n<br>\n\nUse the `tail()` function to see the last five rows.\n\n```{r}\n#| echo: true\n\ntail(jobs_program)\n```\n\n## \n\n<br>\n\nNow let's visualize it with a bar chart.\n\n```{r}\njobs_program %>%\n  ggplot(aes(x = outcome)) +\n  geom_bar(fill = \"steelblue\") + theme_bw()\n```\n\n## Question\n\n<br>\n\nIs it possible to assess this hypothetical organization's claim using the data and information presented thus far?\n\n>\"Our jobs program is a success because only 15 of the 60 people that we trained did not have a job. Thus our 25% unemployment rate beats the country's unemployment rate of 30%.\"\n\n## Correlation vs. causation\n\n<br>\n\n-   No.\n- We need to know more about how people were selected for the program in order to assess causality (e.g., were they randomly assigned?)\n-   But, we can still ask whether the unemployment rate of $\\hat{p}$ = `r round(15/60, 3)` could be due to chance.\n\n## Hypothesis Testing Intuition {.smaller}\n\n<br>\n\n- We are going to assume \"nothing is going on\"\n    - In this case, the jobs program had no impact\n\n. . .\n\n- We are going to figure out what the distribution of outcomes we we might observe could be if nothing is going on\n    - In this case: if we take a sample of 60 from a population where the parameter is 0.3\n\n. . .\n\n- We will assess how likely we would be to observe our data if nothing is going on\n    - If very unlikely, we conclude that something is probably going on\n\n## Stating our Hypotheses\n\n<br>\n\n**Null hypothesis ($H_0$):** \"There is nothing going on.\"\n\n> Unemployment rate among those in the jobs program is no different than the country average of 30%.\n\n. . .\n\n**Alternative hypothesis ($H_A$):** \"There is something going on.\"\n\n> Unemployment rate is **lower** than the country average of 30%.\n\n\n## Hypothesis Test\n\n<br>\n\n::: incremental\n- **Hypothesis test:** If the null hypothesis were true, is the data we have in our sample likely to have been generated by chance (due to random variability)?\n- If yes, we do NOT reject the null hypothesis\n- If not very likely, we reject the null hypothesis \n:::\n\n## Hypothesis Testing Framework \n\n::: incremental\n-   Start with null hypothesis, $H_0$, represents the status quo\n-   Set an alternative hypothesis, $H_A$, that represents the research question, i.e. what we're testing for\n-   Conduct a hypothesis test under the assumption that the null hypothesis is true \n    -   if the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\n    -   if they do, then reject the null hypothesis in favor of the alternative\n:::\n\n## p-values and Critical Values\n\n<br>\n\n::: incremental\n- A **p-value** is the probability of observed or more extreme outcome given that the null hypothesis is true\n- A critical value ($\\alpha$) is the threshold at which we will reject the null hypothesis\n- If the p-value is less than $\\alpha$, we reject the null hypothesis\n- A standard threshold for $\\alpha$ is 0.05\n:::\n\n## The Null Distribution\n\n<br>\n\n-   Since $H_0: p = 0.30$, we need to simulate a null distribution where the probability of success (unemployment) for each trial (person in program) is 0.30\n\n. . .\n\n-   We want to know how likely we would be to get an unemployment rate of 0.25 in our sample of 60, *if the true unemployment rate were 0.30*\n\n\n## What do we expect?\n\n<br>\n\n::: incremental\n- So the first step is to simulate our null distribution\n- And the question is, when sampling from the null distribution, what is the expected proportion of unemployed?\n- We set up our simulator to select samples of 60 individuals with a 30% chance of being unemployed\n- We then calculate the proportion of unemployed in each sample\n:::\n\n## Simulation #1\n\n```{r} \n#| out-width: 50%\n\n# set seed\nset.seed(12112021)\n# create sample space\noutcomes <- c(\"unemployed\", \"employed\")\n# draw the first sample of size 60 from the null distribution\nsim1 <- sample(outcomes, size = 60, prob = c(0.3, 0.7), replace = TRUE)\n# view the sample\ntable(sim1)\n# calculate the simulated sample proportion \n(p_hat_sim1 <- sum(sim1 == \"unemployed\") / length(sim1))\n\n# create an empty data frame\nsim_dist <- data.frame(p_hat_sim = rep(NA, 3))\n\n# record the simulated p-hat as the first observation\nsim_dist$p_hat_sim[1] <- p_hat_sim1\n\n# plot\nggplot(sim_dist, aes(x = p_hat_sim)) + \n  geom_dotplot() + \n  xlim(0, 0.5) + ylim(0, 10)\n```\n\n------------------------------------------------------------------------\n\n## Simulation #2\n\n```{r}\n#| out-width: 50%\n\nsim2 <- sample(outcomes, size = 60, prob = c(0.3, 0.7), replace = TRUE)\n\ntable(sim2)\n\n(p_hat_sim2 <- sum(sim2 == \"unemployed\") / length(sim2))\n\nsim_dist$p_hat_sim[2] <- p_hat_sim2\n\nggplot(sim_dist, aes(x = p_hat_sim)) + \n  geom_dotplot() + \n  xlim(0,0.5) + ylim(0,10)\n```\n\n## Simulation #3\n\n```{r}\n#| out-width: 50%\n\nsim3 <- sample(outcomes, size = 60, prob = c(0.3, 0.7), replace = TRUE)\n\ntable(sim3)\n\n(p_hat_sim3 <- sum(sim3 == \"unemployed\") / length(sim3))\n\nsim_dist$p_hat_sim[3] <- p_hat_sim3\n\nggplot(sim_dist, aes(x = p_hat_sim)) + \n  geom_dotplot() + \n  xlim(0,0.5) + ylim(0,10)\n```\n\n## We need to do this many times...\n\n## `tidymodels`\n\n<br>\n\nWe can use the `tidymodels` package to help with this process...\n\n```{r}\n#| echo: true\n\n#load tidymodels\nlibrary(tidymodels)\n\n# simulate the distribution\nnull_dist <- jobs_program |>\n  specify(response = outcome, success = \"unemployed\") |>\n  hypothesize(null = \"point\", p = c(\"unemployed\" = 0.30, \"employed\" = 0.70)) |>\n  generate(reps = 2000, type = \"draw\") |> \n  calculate(stat = \"prop\")\n```\n\n## What is being stored in *null_dist*?\n\n<br>\n\n```{r}\nnull_dist |>\n  mutate(\n    replicate = as.numeric(replicate),\n    stat = round(stat, 3)\n    )\n```\n\n## The null distribution\n\n<br>\n\nWhere should this distribution be centered?  Or, what should the mean be?\n\n<br>\n\n. . .\n\n```{r}\n#| echo: true \n\nnull_dist |>\n  summarize(mean = mean(stat))\n```\n\n## Visualizing the null distribution\n\n```{r out.width=\"40%\"}\nggplot(data = null_dist, mapping = aes(x = stat)) +\n  geom_histogram(binwidth = 0.05, fill = \"steelblue4\") +\n  labs(title = \"Null distribution\")  + theme_bw()\n```\n\n## Calculate the p-value\n\n<br> \n*p-value*--in what % of the simulations was the simulated sample proportion at least as extreme as the observed sample proportion?\n\n```{r}\n#| echo: true\n\nnull_dist |>\n  # select out the value in the null distribution that are less that 0.25\n  filter(stat <= (15/60)) |>\n  # calculate the proportion - (number less divided by all values in null_dist)\n  summarise(p_value = n()/nrow(null_dist))\n```\n\n## Visualizing the p-value\n\n```{r echo=FALSE, out.width=\"50%\"}\nggplot(data = null_dist, mapping = aes(x = stat)) +\n  geom_histogram(binwidth = 0.05, fill = \"steelblue4\") +\n  labs(title = \"Null distribution\") +     \n  geom_vline(xintercept = .25, linetype=\"dotted\", \n                color = \"black\", size=1) + theme_bw()\n```\n\n## \"Significance\" level {.smaller}\n\n<br>\n\n::: incremental\n- Conventionally, people use a p-value of *0.05* as a cutoff (\"signifigance level\") for determining \"statistical significance\"\n    - That is, whether the null hypothesis should be rejected\n    - That is, whether the data we gathered is very unlikely to have been generated due to chance\n- Always remember that this is a convention\n    - *p=0.049* is under the cutoff, while p=0.051 is not: are these really different?\n- When people report \"statistically significant\" results, they mean that the p-value from their analysis is less than 0.05\n:::\n\n## Our Hypothetical Study\n\n<br>\n\n- Our finding: if the true unemployment rate were 30 percent and we draw samples of 60, about 23 percent of the time we will get an unemployment rate lower than the one among the participants in the program (simply due to random chance)\n- What should we conclude?\n\n## Conclusion\n\n<br>\n\n- We do NOT reject the null hypothesis: the unemployment rate in the sample could likely have been due to chance\n\n## Your Turn!\n\n- What if the unemployment rate for the program was only 10%?     - Would you reject the null hypothesis in this case?\n    - Demonstrate by calculating the p-value\n- Try changing the true unemployment rate in the null distribution to 0.50 (50%)\n  - Simulate the null distribution\n  - Would you reject the null hypothesis if the observed unemployment rate was 23% in this case?\n\n# Associations Between Two Variables\n\n## Hypotheses\n\n<br>\n\n- **Null hypothesis:** there is no relationship between treatment and outcome, the difference is due to chance\n- **Alternative hypothesis:** there is a relationship, the difference is not due to chance\n\n## Approach\n\n<br>\n\n- Under the null hypothesis, treatment has **NO** impact on *y* (the outcome)\n- This means that if we were to change the values of the treatment variable, the values on *y* **would stay the same**\n\n## Approach\n\n- So...we can simulate the null distribution by:\n    - Reshuffling the treatment variable\n    - Calculating the treatment effect\n    - Repeating many times\n    \n. . . \n\n- Then we can ask: how likely would we be to observe the treatment effect in our data, *if there is no effect of the treatment*?\n\n## Résumé Experiment Example\n\nBertrand and Mullainathan studied racial discrimination in responses to job applications in Chicago and Boston. They sent 4,870 résumés, randomly assigning names associated with different racial groups.\n- Data are in `openintro` package as an object called `resume`\n- I will save as `myDat`\n\n```{r}\nlibrary(openintro)\nmyDat <- resume \n```\n\n## Callbacks by Race\n\n<br>\n\nRemember, race of applicant is randomly assigned.\n\n```{r}\nlibrary(tidyverse)\n\nmns <- myDat |>\n  group_by(race) |> \n  summarize(calls = mean(received_callback))\nmns\n```\n\n##\n\n<br> \n\nLet's save the means for white and black applicants.\n\n<br>\n\n```{r}\nmean_white = mns$calls[2]\nmean_black = mns$calls[1]\n```\n\n##\n\n<br>\n\nAnd calculate the treatment effect. The treatment effect is the difference in means.\n\n<br>\n\n```{r}\nteffect <- mean_white - mean_black\nteffect\n```\n\n## {.center}\n\nBefore formal tests, let's look at the data--the estimates **and** the confidence intervals...\n\n##\n\n<br>\n\nFirst, let's make the CIs for the white applicants.\n\n<br>\n\n```{r}\nlibrary(tidymodels)\nboot_df_white <- myDat |>\n  filter(race == \"white\") |> \n  specify(response = received_callback) |>  \n  generate(reps = 15000, type = \"bootstrap\") |> \n  calculate(stat = \"mean\")\nlower_bound_white <- boot_df_white |> summarize(lower_bound_white = quantile(stat, 0.025)) |> pull() \nupper_bound_white <- boot_df_white |> summarize(upper_bound_white = quantile(stat, 0.975)) |> pull() \n```\n\n## \n\n<br>\n\nNow, let's create the CIs for black applicants.\n\n<br>\n\n```{r}\nboot_df_black <- myDat |>\n  filter(race == \"black\") |> \n  specify(response = received_callback) |>  \n  generate(reps = 15000, type = \"bootstrap\") |> \n  calculate(stat = \"mean\")\nlower_bound_black <- boot_df_black |> summarize(lower_bound_black = quantile(stat, 0.025)) |> pull() \nupper_bound_black <- boot_df_black |> summarize(upper_bound_black = quantile(stat, 0.975)) |> pull() \n```\n\n## \n\n<br>\n\nNow, let's tidy the data for plotting.\n\n<br>\n\n```{r}\nplotData <- tibble(\n  race = c(\"Black\", \"White\"),\n  meanCalls = c(mean_black, mean_white),\n  lower95 = c(lower_bound_black, lower_bound_white),\n  upper95 = c(upper_bound_black, upper_bound_white)\n)\nplotData\n```\n\n## Plot\n\n```{r}\n#| echo: false\n\nggplot(plotData, aes(y = meanCalls, x = race, ymin = lower95, ymax = upper95)) +\n  geom_col(fill = \"steelblue4\") +\n  geom_errorbar(width = .05) +\n  theme_bw()  +\n ylim(0, .15) +\n  labs(x = \"Race of Applicant\",\n       y = \"Call Back Rate\")\n```\n\n## Plot\n\n<br>\n\n```{r}\n#| echo: true\n#| eval: false\n\nggplot(plotData, aes(y = meanCalls, x = race, ymin = lower95, ymax = upper95)) +\n  geom_col(fill = \"steelblue4\") +\n  geom_errorbar(width = .05) +\n  theme_bw()  +\n  ylim(0, .15) +\n  labs(x = \"Race of Applicant\",\n       y = \"Call Back Rate\")\n```\n\n## Is this evidence of racial discrimination?\n\n<br>\n\n- What is the null hypothesis?\n\n. . .\n\n- What is the alternative hypothesis?\n\n. . .\n\n- How can we formally test the null hypothesis to decide whether to reject it?\n\n## Formal Hypothesis Test\n\n<br>\n\n::: incremental\n- Calculate the difference in means (White - Black)\n- Shuffle the race variable\n- Calculate the difference in means for the shuffled data\n- Repeat many times\n- Simulates the null distribution of **differences** in callbacks\n:::\n\n## Hypothetical Original Data \n\n<br>\n\n| Applicant | Race  | Callback |\n|-----------|-------|----------|\n| A         | Black | Yes      |\n| B         | Black | No       |\n| C         | Black | No       |\n| D         | White | Yes      |\n| E         | White | No       |\n| F         | White | No       |\n\n## Step 1: Calculate Original Difference in Callback Rates\n\n<br> \n\n- **Objective:** Understand initial association between race and callback rates\n\n## Step 2: Shuffle (Permute) the Race Variable\n\n<br>\n\n- **Method:** Randomly reassign race labels, keeping callback outcomes fixed\n\n## Hypothetical Shuffled Data\n\n<br>\n\n| Applicant | Race (Shuffled) | Callback |\n|-----------|-----------------|----------|\n| A         | White           | Yes      |\n| B         | Black           | No       |\n| C         | White           | No       |\n| D         | White           | Yes      |\n| E         | Black           | No       |\n| F         | Black           | No       |\n\n## Step 3: Calculate Difference in Callback Rates Again\n\n<br> \n\n- **After Shuffling:** Calculate the difference in callback rates between Black and White groups\n- **Purpose:** Determine if observed difference is due to chance\n\n## Repeat Many Times\n\n<br>\n\n- Repeat shuffling 5000 times to generate a distribution of differences by chance\n- **Test:** Compare observed difference to null distribution to assess effect of race on callbacks\n- If observed difference is extreme (p-value is low), reject the null hypothesis\n\n## Simulating with `tidymodels`\n\n<br>\n\nIn real life we are going to use the `tidymodels` package to do the simulation for us.\n\n```{r}\nnull_dist <- myDat |>\n  specify(response = received_callback, explanatory = race) |>\n  hypothesize(null = \"independence\") |>\n  generate(5000, type = \"permute\") |>\n  calculate(stat = \"diff in means\", \n            order = c(\"white\", \"black\")) # \n```\n\n## Visualize\n\n```{r}\n#| echo: false\n\nggplot(data = null_dist, mapping = aes(x = stat)) +\n  geom_histogram(binwidth = 0.01, fill = \"steelblue4\") +\n  labs(title = \"Null distribution + Estimate\",\n       x = \"Estimated Difference under the Null\") +     \n  geom_vline(xintercept = teffect, linetype=\"dotted\", \n                color = \"black\", size=1) + theme_bw()\n```\n\n## Visualize\n\n<br>\n\n```{r}\n#| echo: true\n#| eval: false\n\nggplot(data = null_dist, mapping = aes(x = stat)) +\n  geom_histogram(binwidth = 0.01, fill = \"steelblue4\") +\n  labs(title = \"Null distribution + Estimate\",\n       x = \"Estimated Difference under the Null\") +     \n  geom_vline(xintercept = teffect, linetype=\"dotted\", \n                color = \"black\", size=1) + theme_bw()\n```\n\n## Calculate the p-value\n\n<br>\n\n```{r}\n#| echo: false\n\noptions(scipen = 999, digits = 10) # to avoid scientific notation\n```\n\n```{r}\nnull_dist |>\n  filter(stat > teffect) |>\n  summarise(p_value = n()/nrow(null_dist)) \n```\n\n## What should we conclude?\n\n<br>\n\n::: incremental\n- The p-value is very small (below .05 threshold)\n- Therefore, we **reject** the null hypothesis: the racial gap is extremely unlikely to have occurred due to chance alone\n- This is evidence of racial discrimination\n:::\n\n## Your Turn! {.smaller}\n\n<br>\n\n- Use the **gender** variable in the `resume` data to assess whether there is gender discrimination in call backs\n- Plot means and 95% confidence intervals for the call back rate for men and women\n- Write the null and alternative hypotheses\n- Simulate the null distribution\n- Visualize the null distribution and the gender gap\n- Calculate the p-value\n- What do you conclude from your test?  \n\n\n","srcMarkdownNoYaml":"\n\n# Hypothesis Test for a Single Proportion\n\n## Jobs Training Programs\n\n-   International development organizations are sometimes interested in providing training to people in order to help them find a job\n-   Imagine the unemployment rate in a low-income country is 30%\n-   One organization claims that its jobs training program is a success because only 15 of the 60 people that they trained did not have a job (25% unemployment rate)\n-   What should we think about this claim? Is this a successful program?\n\n## Today's Code\n\n<https://www.dropbox.com/scl/fo/g4tdpdwcij78nyydvr4bp/h?rlkey=hctskhle6222csnwre5ir9gz3&dl=0>\n\n## \n\n<br>\n\nNow let's create some data to match our hypothetical example.\n\n<br>\n\n```{r}\n#| echo: true\n\nlibrary(tidyverse)\n\njobs_program <- tibble(\n  outcome = c(rep(\"unemployed\", 15), rep(\"employed\", 45))\n)\n\n```\n\n## \n\n<br>\n\nUse the base R `head()` function to see the first five rows.\n\n```{r}\n#| echo: true\n\nhead(jobs_program)\n```\n\n## \n\n<br>\n\nUse the `tail()` function to see the last five rows.\n\n```{r}\n#| echo: true\n\ntail(jobs_program)\n```\n\n## \n\n<br>\n\nNow let's visualize it with a bar chart.\n\n```{r}\njobs_program %>%\n  ggplot(aes(x = outcome)) +\n  geom_bar(fill = \"steelblue\") + theme_bw()\n```\n\n## Question\n\n<br>\n\nIs it possible to assess this hypothetical organization's claim using the data and information presented thus far?\n\n>\"Our jobs program is a success because only 15 of the 60 people that we trained did not have a job. Thus our 25% unemployment rate beats the country's unemployment rate of 30%.\"\n\n## Correlation vs. causation\n\n<br>\n\n-   No.\n- We need to know more about how people were selected for the program in order to assess causality (e.g., were they randomly assigned?)\n-   But, we can still ask whether the unemployment rate of $\\hat{p}$ = `r round(15/60, 3)` could be due to chance.\n\n## Hypothesis Testing Intuition {.smaller}\n\n<br>\n\n- We are going to assume \"nothing is going on\"\n    - In this case, the jobs program had no impact\n\n. . .\n\n- We are going to figure out what the distribution of outcomes we we might observe could be if nothing is going on\n    - In this case: if we take a sample of 60 from a population where the parameter is 0.3\n\n. . .\n\n- We will assess how likely we would be to observe our data if nothing is going on\n    - If very unlikely, we conclude that something is probably going on\n\n## Stating our Hypotheses\n\n<br>\n\n**Null hypothesis ($H_0$):** \"There is nothing going on.\"\n\n> Unemployment rate among those in the jobs program is no different than the country average of 30%.\n\n. . .\n\n**Alternative hypothesis ($H_A$):** \"There is something going on.\"\n\n> Unemployment rate is **lower** than the country average of 30%.\n\n\n## Hypothesis Test\n\n<br>\n\n::: incremental\n- **Hypothesis test:** If the null hypothesis were true, is the data we have in our sample likely to have been generated by chance (due to random variability)?\n- If yes, we do NOT reject the null hypothesis\n- If not very likely, we reject the null hypothesis \n:::\n\n## Hypothesis Testing Framework \n\n::: incremental\n-   Start with null hypothesis, $H_0$, represents the status quo\n-   Set an alternative hypothesis, $H_A$, that represents the research question, i.e. what we're testing for\n-   Conduct a hypothesis test under the assumption that the null hypothesis is true \n    -   if the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\n    -   if they do, then reject the null hypothesis in favor of the alternative\n:::\n\n## p-values and Critical Values\n\n<br>\n\n::: incremental\n- A **p-value** is the probability of observed or more extreme outcome given that the null hypothesis is true\n- A critical value ($\\alpha$) is the threshold at which we will reject the null hypothesis\n- If the p-value is less than $\\alpha$, we reject the null hypothesis\n- A standard threshold for $\\alpha$ is 0.05\n:::\n\n## The Null Distribution\n\n<br>\n\n-   Since $H_0: p = 0.30$, we need to simulate a null distribution where the probability of success (unemployment) for each trial (person in program) is 0.30\n\n. . .\n\n-   We want to know how likely we would be to get an unemployment rate of 0.25 in our sample of 60, *if the true unemployment rate were 0.30*\n\n\n## What do we expect?\n\n<br>\n\n::: incremental\n- So the first step is to simulate our null distribution\n- And the question is, when sampling from the null distribution, what is the expected proportion of unemployed?\n- We set up our simulator to select samples of 60 individuals with a 30% chance of being unemployed\n- We then calculate the proportion of unemployed in each sample\n:::\n\n## Simulation #1\n\n```{r} \n#| out-width: 50%\n\n# set seed\nset.seed(12112021)\n# create sample space\noutcomes <- c(\"unemployed\", \"employed\")\n# draw the first sample of size 60 from the null distribution\nsim1 <- sample(outcomes, size = 60, prob = c(0.3, 0.7), replace = TRUE)\n# view the sample\ntable(sim1)\n# calculate the simulated sample proportion \n(p_hat_sim1 <- sum(sim1 == \"unemployed\") / length(sim1))\n\n# create an empty data frame\nsim_dist <- data.frame(p_hat_sim = rep(NA, 3))\n\n# record the simulated p-hat as the first observation\nsim_dist$p_hat_sim[1] <- p_hat_sim1\n\n# plot\nggplot(sim_dist, aes(x = p_hat_sim)) + \n  geom_dotplot() + \n  xlim(0, 0.5) + ylim(0, 10)\n```\n\n------------------------------------------------------------------------\n\n## Simulation #2\n\n```{r}\n#| out-width: 50%\n\nsim2 <- sample(outcomes, size = 60, prob = c(0.3, 0.7), replace = TRUE)\n\ntable(sim2)\n\n(p_hat_sim2 <- sum(sim2 == \"unemployed\") / length(sim2))\n\nsim_dist$p_hat_sim[2] <- p_hat_sim2\n\nggplot(sim_dist, aes(x = p_hat_sim)) + \n  geom_dotplot() + \n  xlim(0,0.5) + ylim(0,10)\n```\n\n## Simulation #3\n\n```{r}\n#| out-width: 50%\n\nsim3 <- sample(outcomes, size = 60, prob = c(0.3, 0.7), replace = TRUE)\n\ntable(sim3)\n\n(p_hat_sim3 <- sum(sim3 == \"unemployed\") / length(sim3))\n\nsim_dist$p_hat_sim[3] <- p_hat_sim3\n\nggplot(sim_dist, aes(x = p_hat_sim)) + \n  geom_dotplot() + \n  xlim(0,0.5) + ylim(0,10)\n```\n\n## We need to do this many times...\n\n## `tidymodels`\n\n<br>\n\nWe can use the `tidymodels` package to help with this process...\n\n```{r}\n#| echo: true\n\n#load tidymodels\nlibrary(tidymodels)\n\n# simulate the distribution\nnull_dist <- jobs_program |>\n  specify(response = outcome, success = \"unemployed\") |>\n  hypothesize(null = \"point\", p = c(\"unemployed\" = 0.30, \"employed\" = 0.70)) |>\n  generate(reps = 2000, type = \"draw\") |> \n  calculate(stat = \"prop\")\n```\n\n## What is being stored in *null_dist*?\n\n<br>\n\n```{r}\nnull_dist |>\n  mutate(\n    replicate = as.numeric(replicate),\n    stat = round(stat, 3)\n    )\n```\n\n## The null distribution\n\n<br>\n\nWhere should this distribution be centered?  Or, what should the mean be?\n\n<br>\n\n. . .\n\n```{r}\n#| echo: true \n\nnull_dist |>\n  summarize(mean = mean(stat))\n```\n\n## Visualizing the null distribution\n\n```{r out.width=\"40%\"}\nggplot(data = null_dist, mapping = aes(x = stat)) +\n  geom_histogram(binwidth = 0.05, fill = \"steelblue4\") +\n  labs(title = \"Null distribution\")  + theme_bw()\n```\n\n## Calculate the p-value\n\n<br> \n*p-value*--in what % of the simulations was the simulated sample proportion at least as extreme as the observed sample proportion?\n\n```{r}\n#| echo: true\n\nnull_dist |>\n  # select out the value in the null distribution that are less that 0.25\n  filter(stat <= (15/60)) |>\n  # calculate the proportion - (number less divided by all values in null_dist)\n  summarise(p_value = n()/nrow(null_dist))\n```\n\n## Visualizing the p-value\n\n```{r echo=FALSE, out.width=\"50%\"}\nggplot(data = null_dist, mapping = aes(x = stat)) +\n  geom_histogram(binwidth = 0.05, fill = \"steelblue4\") +\n  labs(title = \"Null distribution\") +     \n  geom_vline(xintercept = .25, linetype=\"dotted\", \n                color = \"black\", size=1) + theme_bw()\n```\n\n## \"Significance\" level {.smaller}\n\n<br>\n\n::: incremental\n- Conventionally, people use a p-value of *0.05* as a cutoff (\"signifigance level\") for determining \"statistical significance\"\n    - That is, whether the null hypothesis should be rejected\n    - That is, whether the data we gathered is very unlikely to have been generated due to chance\n- Always remember that this is a convention\n    - *p=0.049* is under the cutoff, while p=0.051 is not: are these really different?\n- When people report \"statistically significant\" results, they mean that the p-value from their analysis is less than 0.05\n:::\n\n## Our Hypothetical Study\n\n<br>\n\n- Our finding: if the true unemployment rate were 30 percent and we draw samples of 60, about 23 percent of the time we will get an unemployment rate lower than the one among the participants in the program (simply due to random chance)\n- What should we conclude?\n\n## Conclusion\n\n<br>\n\n- We do NOT reject the null hypothesis: the unemployment rate in the sample could likely have been due to chance\n\n## Your Turn!\n\n- What if the unemployment rate for the program was only 10%?     - Would you reject the null hypothesis in this case?\n    - Demonstrate by calculating the p-value\n- Try changing the true unemployment rate in the null distribution to 0.50 (50%)\n  - Simulate the null distribution\n  - Would you reject the null hypothesis if the observed unemployment rate was 23% in this case?\n\n# Associations Between Two Variables\n\n## Hypotheses\n\n<br>\n\n- **Null hypothesis:** there is no relationship between treatment and outcome, the difference is due to chance\n- **Alternative hypothesis:** there is a relationship, the difference is not due to chance\n\n## Approach\n\n<br>\n\n- Under the null hypothesis, treatment has **NO** impact on *y* (the outcome)\n- This means that if we were to change the values of the treatment variable, the values on *y* **would stay the same**\n\n## Approach\n\n- So...we can simulate the null distribution by:\n    - Reshuffling the treatment variable\n    - Calculating the treatment effect\n    - Repeating many times\n    \n. . . \n\n- Then we can ask: how likely would we be to observe the treatment effect in our data, *if there is no effect of the treatment*?\n\n## Résumé Experiment Example\n\nBertrand and Mullainathan studied racial discrimination in responses to job applications in Chicago and Boston. They sent 4,870 résumés, randomly assigning names associated with different racial groups.\n- Data are in `openintro` package as an object called `resume`\n- I will save as `myDat`\n\n```{r}\nlibrary(openintro)\nmyDat <- resume \n```\n\n## Callbacks by Race\n\n<br>\n\nRemember, race of applicant is randomly assigned.\n\n```{r}\nlibrary(tidyverse)\n\nmns <- myDat |>\n  group_by(race) |> \n  summarize(calls = mean(received_callback))\nmns\n```\n\n##\n\n<br> \n\nLet's save the means for white and black applicants.\n\n<br>\n\n```{r}\nmean_white = mns$calls[2]\nmean_black = mns$calls[1]\n```\n\n##\n\n<br>\n\nAnd calculate the treatment effect. The treatment effect is the difference in means.\n\n<br>\n\n```{r}\nteffect <- mean_white - mean_black\nteffect\n```\n\n## {.center}\n\nBefore formal tests, let's look at the data--the estimates **and** the confidence intervals...\n\n##\n\n<br>\n\nFirst, let's make the CIs for the white applicants.\n\n<br>\n\n```{r}\nlibrary(tidymodels)\nboot_df_white <- myDat |>\n  filter(race == \"white\") |> \n  specify(response = received_callback) |>  \n  generate(reps = 15000, type = \"bootstrap\") |> \n  calculate(stat = \"mean\")\nlower_bound_white <- boot_df_white |> summarize(lower_bound_white = quantile(stat, 0.025)) |> pull() \nupper_bound_white <- boot_df_white |> summarize(upper_bound_white = quantile(stat, 0.975)) |> pull() \n```\n\n## \n\n<br>\n\nNow, let's create the CIs for black applicants.\n\n<br>\n\n```{r}\nboot_df_black <- myDat |>\n  filter(race == \"black\") |> \n  specify(response = received_callback) |>  \n  generate(reps = 15000, type = \"bootstrap\") |> \n  calculate(stat = \"mean\")\nlower_bound_black <- boot_df_black |> summarize(lower_bound_black = quantile(stat, 0.025)) |> pull() \nupper_bound_black <- boot_df_black |> summarize(upper_bound_black = quantile(stat, 0.975)) |> pull() \n```\n\n## \n\n<br>\n\nNow, let's tidy the data for plotting.\n\n<br>\n\n```{r}\nplotData <- tibble(\n  race = c(\"Black\", \"White\"),\n  meanCalls = c(mean_black, mean_white),\n  lower95 = c(lower_bound_black, lower_bound_white),\n  upper95 = c(upper_bound_black, upper_bound_white)\n)\nplotData\n```\n\n## Plot\n\n```{r}\n#| echo: false\n\nggplot(plotData, aes(y = meanCalls, x = race, ymin = lower95, ymax = upper95)) +\n  geom_col(fill = \"steelblue4\") +\n  geom_errorbar(width = .05) +\n  theme_bw()  +\n ylim(0, .15) +\n  labs(x = \"Race of Applicant\",\n       y = \"Call Back Rate\")\n```\n\n## Plot\n\n<br>\n\n```{r}\n#| echo: true\n#| eval: false\n\nggplot(plotData, aes(y = meanCalls, x = race, ymin = lower95, ymax = upper95)) +\n  geom_col(fill = \"steelblue4\") +\n  geom_errorbar(width = .05) +\n  theme_bw()  +\n  ylim(0, .15) +\n  labs(x = \"Race of Applicant\",\n       y = \"Call Back Rate\")\n```\n\n## Is this evidence of racial discrimination?\n\n<br>\n\n- What is the null hypothesis?\n\n. . .\n\n- What is the alternative hypothesis?\n\n. . .\n\n- How can we formally test the null hypothesis to decide whether to reject it?\n\n## Formal Hypothesis Test\n\n<br>\n\n::: incremental\n- Calculate the difference in means (White - Black)\n- Shuffle the race variable\n- Calculate the difference in means for the shuffled data\n- Repeat many times\n- Simulates the null distribution of **differences** in callbacks\n:::\n\n## Hypothetical Original Data \n\n<br>\n\n| Applicant | Race  | Callback |\n|-----------|-------|----------|\n| A         | Black | Yes      |\n| B         | Black | No       |\n| C         | Black | No       |\n| D         | White | Yes      |\n| E         | White | No       |\n| F         | White | No       |\n\n## Step 1: Calculate Original Difference in Callback Rates\n\n<br> \n\n- **Objective:** Understand initial association between race and callback rates\n\n## Step 2: Shuffle (Permute) the Race Variable\n\n<br>\n\n- **Method:** Randomly reassign race labels, keeping callback outcomes fixed\n\n## Hypothetical Shuffled Data\n\n<br>\n\n| Applicant | Race (Shuffled) | Callback |\n|-----------|-----------------|----------|\n| A         | White           | Yes      |\n| B         | Black           | No       |\n| C         | White           | No       |\n| D         | White           | Yes      |\n| E         | Black           | No       |\n| F         | Black           | No       |\n\n## Step 3: Calculate Difference in Callback Rates Again\n\n<br> \n\n- **After Shuffling:** Calculate the difference in callback rates between Black and White groups\n- **Purpose:** Determine if observed difference is due to chance\n\n## Repeat Many Times\n\n<br>\n\n- Repeat shuffling 5000 times to generate a distribution of differences by chance\n- **Test:** Compare observed difference to null distribution to assess effect of race on callbacks\n- If observed difference is extreme (p-value is low), reject the null hypothesis\n\n## Simulating with `tidymodels`\n\n<br>\n\nIn real life we are going to use the `tidymodels` package to do the simulation for us.\n\n```{r}\nnull_dist <- myDat |>\n  specify(response = received_callback, explanatory = race) |>\n  hypothesize(null = \"independence\") |>\n  generate(5000, type = \"permute\") |>\n  calculate(stat = \"diff in means\", \n            order = c(\"white\", \"black\")) # \n```\n\n## Visualize\n\n```{r}\n#| echo: false\n\nggplot(data = null_dist, mapping = aes(x = stat)) +\n  geom_histogram(binwidth = 0.01, fill = \"steelblue4\") +\n  labs(title = \"Null distribution + Estimate\",\n       x = \"Estimated Difference under the Null\") +     \n  geom_vline(xintercept = teffect, linetype=\"dotted\", \n                color = \"black\", size=1) + theme_bw()\n```\n\n## Visualize\n\n<br>\n\n```{r}\n#| echo: true\n#| eval: false\n\nggplot(data = null_dist, mapping = aes(x = stat)) +\n  geom_histogram(binwidth = 0.01, fill = \"steelblue4\") +\n  labs(title = \"Null distribution + Estimate\",\n       x = \"Estimated Difference under the Null\") +     \n  geom_vline(xintercept = teffect, linetype=\"dotted\", \n                color = \"black\", size=1) + theme_bw()\n```\n\n## Calculate the p-value\n\n<br>\n\n```{r}\n#| echo: false\n\noptions(scipen = 999, digits = 10) # to avoid scientific notation\n```\n\n```{r}\nnull_dist |>\n  filter(stat > teffect) |>\n  summarise(p_value = n()/nrow(null_dist)) \n```\n\n## What should we conclude?\n\n<br>\n\n::: incremental\n- The p-value is very small (below .05 threshold)\n- Therefore, we **reject** the null hypothesis: the racial gap is extremely unlikely to have occurred due to chance alone\n- This is evidence of racial discrimination\n:::\n\n## Your Turn! {.smaller}\n\n<br>\n\n- Use the **gender** variable in the `resume` data to assess whether there is gender discrimination in call backs\n- Plot means and 95% confidence intervals for the call back rate for men and women\n- Write the null and alternative hypotheses\n- Simulate the null distribution\n- Visualize the null distribution and the gender gap\n- Calculate the p-value\n- What do you conclude from your test?  \n\n\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","output-file":"week-4.2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.4.533","auto-stretch":true,"editor":"source","title":"Hypothesis Testing","date":"today","date-format":"long","footer":"[IAFF 6501 Website](https://quant4ia.rocks/)","logo":"images/iaff6501-logo.png","theme":["simple","custom.scss"],"transition":"fade","slideNumber":true,"chalkboard":true}}},"projectFormats":["html"]}