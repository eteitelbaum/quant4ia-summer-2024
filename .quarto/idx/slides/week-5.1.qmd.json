{"title":"Linear Regression","markdown":{"yaml":{"title":"Linear Regression","date":"today","date-format":"long","footer":"[IAFF 6501 Website](https://quant4ia.rocks/)","logo":"images/iaff6501-logo.png","format":{"revealjs":{"theme":["simple","custom.scss"],"transition":"fade","slide-number":true,"chalkboard":true}},"execute":{"echo":false,"message":false,"warning":false,"freeze":"auto"}},"headingText":"Modeling","containsRefs":false,"markdown":"\n\n\n```{r} \n#| label: packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(vdemdata)\n\nset.seed(1234)\n```\n\n\n::: {.incremental}\n- Use models to explain the relationship between variables and to make predictions\n- Explaining relationships [usually interested in causal relationships, but not always]\n    - Does oil wealth impact regime type?\n- Predictive modeling\n    - Where is violence most likely to happen in [country X] during their next election?\n    - Is this email spam?\n:::\n    \n## Modeling\n\n```{r}\n#| label: linear-model\n\ndf1 <- tibble(x = 1:100, y = x + rnorm(100, mean = 0, sd = 5))\n\nggplot(df1, aes(x = x, y = y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(title = \"Linear\", x = NULL, y = NULL) +\n  theme_bw()\n```\n\n## Modeling\n\n```{r}\n#| label: nonlinear-model\n\ndf2 <- tibble(x = seq(-6, 5.9, 0.1), y = (1 / (1+exp(-2*x))) + rnorm(120, mean = 0, sd = 0.1))\n\nggplot(df2, aes(x = x, y = y)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", color = \"#8E2C90\", se = FALSE) +\n  labs(title = \"Non-linear\", x = NULL, y = NULL) +\n  theme_bw()\n```\n\n# Example: GDP per capita and Democracy\n\n## Pull in the VDEM Data\n\n<br>\n\nWhat is this code doing?\n\n```{r}\n#| label: wrangle-vdem\n#| echo: true\n\nlibrary(vdemdata)\n\nmodelData <- vdem |>\n  filter(year == 2019) |> \n  select(\n    country = country_name, \n    lib_dem = v2x_libdem, \n    wealth = e_gdppc) |>\n  mutate(log_wealth = log(wealth))\n\nglimpse(modelData)\n```\n\n## Plot the Relationship\n\n```{r}\n#| label: plot-wealth-dem-1\n\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n#  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(\n    title = \"Wealth and Democracy, 2019\",\n    x = \"GPD per capita\", \n    y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n## Plot the Relationship\n\n```{r}\n#| label: plot-wealth-dem-2\n\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(\n    title = \"Wealth and Democracy, 2019\",\n    x = \"GPD per capita\", \n    y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n## Plot the Relationship\n\n<br>\n\n```{r}\n#| label: plot-wealth-dem-3\n#| echo: true\n#| eval: false\n\nggplot(modelData, aes(x = wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GPD per capita\", y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n## Using the Scales Package\n\n\n```{r}\n#| label: plot-wealth-dem-4\n\nggplot(modelData, aes(x = wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  scale_x_log10(label = scales::label_dollar(suffix = \"k\")) +\n  labs(\n    title = \"Wealth and Democracy, 2019\",\n    x = \"GPD per capita\", \n    y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n## Using the Scales Package\n\n<br>\n\n```{r}\n#| label: plot-wealth-dem-5\n#| code-line-numbers: \"1,4\"\n#| echo: true\n#| eval: false\n\nggplot(modelData, aes(x = wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  scale_x_log10(label = scales::label_dollar(suffix = \"k\")) +\n  labs(\n    title = \"Wealth and Democracy, 2019\",\n    x = \"GPD per capita\", \n    y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n## Models as Functions\n\n::: {.incremental}\n- We can represent relationships between variables using **functions**\n- A function is a mathematical concept: the relationship between an output and one or more inputs\n  - Plug in the inputs and receive back the output\n- Example: The formula $y = 3x + 7$ is a function with input $x$ and output $y$. \n    - If $x$ is $5$, $y$ is $22$, \n    - $y = 3 \\times 5 + 7 = 22$\n:::\n\n## Quant Lingo {.smaller}\n\n<br>\n\n::: {.incremental}\n- **Response variable:** Variable whose behavior or variation you are trying to understand, on the y-axis in the plot\n    - **Dependent** variable\n    - **Outcome** variable\n    - **Y** variable\n- **Explanatory variables:** Other variables that you want to use to explain the variation in the response, on the x-axis in the plot\n    - **Independent** variables\n    - **Predictors**\n:::\n\n## \n\n<br>\n\nLinear model with one explanatory variable...\n\n::: {.incremental}\n- $Y = a + bX$\n- $Y$ is the outcome variable\n- $X$ is the explanatory variable\n- $a$ is the intercept: the predicted value of $Y$ when $X$ is equal to 0\n- $b$ is the slope of the line [remember rise over run!]\n:::\n\n## Quant Lingo {.smaller}\n\n<br>\n\n::: {.incremental}\n- **Predicted value:** Output of the **model function**\n   - The model function gives the typical (expected) value of the response variable *conditioning* on the explanatory variables\n   - We often call this $\\hat{Y}$ to differentiate the predicted value from an observed value of Y in the data\n- **Residuals:** A measure of how far each case is from its predicted value (based on a particular model)\n  - Residual = Observed value ($Y$) - Predicted value ($\\hat{Y}$)\n  - How far above/below the expected value each case is\n:::\n\n## Residuals\n\n```{r , echo = FALSE, warning = FALSE, out.width = \"60%\"}\n\nmod_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(lib_dem ~ log_wealth, data = modelData)\n\nfit_tidy <- tidy(mod_fit$fit) \nfit_aug  <- augment(mod_fit$fit) |>\n  mutate(res_cat = ifelse(.resid > 0, TRUE, FALSE))\n\na <- round(fit_tidy$estimate[1], 2)\nb <- round(fit_tidy$estimate[2], 2)\n\nggplot(data = fit_aug) +\n  geom_point(aes(x = log_wealth, y = lib_dem, color = res_cat)) +\n  geom_line(aes(x = log_wealth, y = .fitted), size = 0.75, color = \"#8E2C90\") + \n  labs(\n    title = \"GDP per Capita and Democracy\",\n    x = \"GDP per Capita\",\n    y = \"Libearl Democracy Index\"\n  ) +\n  guides(color = \"none\") +\n  scale_color_manual(values = c(\"#260b27\", \"darkorange\")) +\n  theme_bw()\n#+\n#  geom_text(aes(x = 0, y = 150), label = \"Positive residual\", color = \"#e6b0e7\", hjust = 0, size = 8) +\n # geom_text(aes(x = 150, y = 25), label = \"Negative residual\", color = \"#260b27\", hjust = 0, size = 8)\n\n```\n\n## Linear Model\n\n$\\hat{Y} = a  + b \\times X$\n\n$\\hat{Y} = `r a`  + `r b` \\times X$\n\n```{r echo=FALSE, out.width = \"100%\"}\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GPD per capita\", y = \"Liberal Democracy Index\") +\n  theme_bw()\n#+\n # theme(\n  #  axis.text  = element_blank(),\n   # axis.ticks = element_blank()\n   # )\n```\n\n## Linear Model: Interpretation\n\n<br>\n\n| $\\hat{Y} = a  + b \\times X$\n| $\\hat{Y} = `r a`  + `r b` \\times X$\n\nWhat is the interpretation of our estimate of $a$?\n\n. . .\n\n<br>\n\n| $\\hat{Y} = `r a`  + `r b` \\times 0$\n| $\\hat{Y} = `r a`$\n\n$a$ is our predicted level of democracy when GDP per capita is 0.\n\n\n## Linear Model: Interpretation \n<br>\n\n\n| $\\hat{Y} = a  + b \\times X$\n| $\\hat{Y} = `r a`  + `r b` \\times X$\n\nWhat is interpretation of our estimate of $b$?\n\n. . . \n\n<br>\n\n| $\\hat{Y} = a  + \\frac{Rise}{Run} \\times X$\n| $\\hat{Y} = a  + \\frac{Change Y}{Change X} \\times X$\n\n## Linear Model: Interpretation {.smaller}\n\n<br>\n\n| $b = \\frac{Change Y}{Change X}$\n| $`r b` = \\frac{Change Y}{Change X}$\n| ${Change Y} = `r b` * {ChangeX}$\n\n. . .\n\n<br>\n\n| When $ChangeX = 1$:\n| ${Change Y = `r b`}$\n\n. . .\n\n<br>\n\n| $b$ is the predicted change in $Y$ **associated with** a ONE unit change in X.\n\n## Linear Model: Interpretation\n\n\n```{r echo=FALSE}\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GPD per capita\", y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n## Linear Model: Interpretation\n\n```{r echo=FALSE}\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GPD per capita\", y = \"Liberal Democracy Index\") +\n  geom_segment(aes(x = 2, xend= 3, y=.37, yend=.37), colour=\"darkblue\", linewidth=1.5, arrow = arrow(length = unit(0.5, \"cm\"))) +\n  theme_bw()\n  \n#Ŷ =0.13+0.12×X\n```\n\n## Linear Model: Interpretation\n\n```{r echo=FALSE}\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GPD per capita\", y = \"Liberal Democracy Index\") +\n  geom_segment(aes(x = 2, xend= 3, y=.37, yend=.37), colour=\"darkblue\", linewidth=1.5) +\n  geom_segment(aes(x = 3, xend= 3, y=.37, yend=.49), colour=\"darkblue\", linewidth=1.5, arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_text(x=3.2, y=.43, label=\"0.12\", color=\"darkblue\", size=4) +\n  theme_bw()\n  \n#Ŷ =0.13+0.12×X\n```\n\n\n## Linear Model: Interpretation\n\n<br>\n\nIs this the **causal** effect of GDP per capita on liberal democracy?\n\n. . .\n\n<br>\n\nNo! It is only the association...\n\n. . .\n\n<br>\n\nTo identify causality we need other methods (beyond the scope of this course).\n\n## Your Task\n\n<br> \n\nAn economist is interested in the relationship between years of education and hourly wages.  They estimate a linear model with estimates of $a$ and $b$ as follows:\n\n<br>\n\n$\\hat{Y} = 9 + 1.60*{YrsEdu}$\n\n<br>\n\n| 1. Interpret $a$ and $b$\n| 2. What is the predicted hourly wage for those with 10 years of education?\n\n## Next step\n\n<br>\n\n- Linear model with one predictor: $Y = a + bX$\n- For any given data...\n- How do we figure out what the best values are for $a$ and $b$??\n\n# Estimation\n\n## Linear Model with Single Predictor\n\n<br>\n\nGoal: Estimate Democracy score ($\\hat{Y_{i}}$) of a country given level of GDP per capita ($X_{i}$).\n\n<br>\n\nOr: Estimate relationship between GDP per capita and democracy.\n\n## Linear Model with Single Predictor\n\n```{r}\n#| label: model-data\n\nmodelData <- vdem |> \n  filter(year == 2019) |> \n  select(\n    country = country_name, \n    lib_dem = v2x_libdem, \n    wealth = e_gdppc, \n    corruption = v2x_corr, \n    ) |>\n  mutate(log_wealth = log(wealth)) \n  \n\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GDP per capita\", y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n# Estimate Model using Tidymodels\n\n## \n\n<br>\n\nStep 1: Specify model\n\n<br>\n\n```{r}\n#| label: specify-model\n#| echo: true\n#| eval: false\n\nlinear_reg()\n```\n\n## \n\n<br>\n\nStep 2: Set model fitting *engine*\n\n<br>\n\n```{r}\n#| label: set-engine\n#| echo: true\n#| eval: false\n\nlinear_reg() |>\n  set_engine(\"lm\") # lm: linear model\n```\n\n## \n\n<br>\n\nStep 3: Fit model & estimate parameters\n\n<bt>\n\n... using **formula syntax**\n\n```{r}\n#| label: fit-model\n#| echo: true\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(lib_dem ~ log_wealth, data = modelData) \n```\n\n## \n\n<br>\n\nStep 4: Tidy things up...\n\n<br>\n\n$$\\widehat{Democracy}_{i} = 0.13 + 0.12 * {loggdppc}_{i}$$\n\n```{r}\n#| label: tidy-model\n#| echo: true\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(lib_dem ~ log_wealth, data = modelData) |>\n  tidy()\n```\n\n\n## Interpretation?\n\n<br>\n\n$$\\widehat{Democracy}_{i} = 0.13 + 0.12 * {loggdppc}_{i}$$\n\n## Question\n\n<br>\n\nHow do we get the \"best\" values for the slope and intercept?\n\n\n## How would you draw the \"best\" line?\n\n```{r}\n#| label: best-line\n\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n # geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GDP per capita\", y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n\n## How would you draw the \"best\" line?\n\n```{r}\n#| label: best-line2\n\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GDP per capita\", y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n## Least squares regression\n\n<br>\n\n- Remember the residual is the difference between the actual value and the predicted value\n\n. . .\n\n- The regression line minimizes the sum of squared residuals.\n\n## Least squares regression\n\n<br>\n\n- Residual for each point is:  $e_i = y_i - \\hat{y}_i$\n\n- Least squares regression line minimizes $\\sum_{i = 1}^n e_i^2$.\n\n. . .\n\n- Why do we square the residual?\n\n. . .\n\n- Why not take absolute value?\n\n    - Principle: larger penalty for residuals further away\n    - Math: makes the math easier and some nice properties (not our concern here...)\n\n## Least squares regression\n\n\n```{r}\n#| label: best-line3 \n\nmod_fit <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(lib_dem ~ log_wealth, data = modelData)\n\nfit_tidy <- tidy(mod_fit$fit) \nfit_aug  <- augment(mod_fit$fit) %>%\n  mutate(res_cat = ifelse(.resid > 0, TRUE, FALSE))\n\na <- round(fit_tidy$estimate[1], 2)\nb <- round(fit_tidy$estimate[2], 2)\n\nggplot(data = fit_aug) +\n  geom_point(aes(x = log_wealth, y = lib_dem, color = res_cat)) +\n  geom_line(aes(x = log_wealth, y = .fitted), size = 0.75, color = \"#8E2C90\") + \n  labs(\n    title = \"GDP per Capita and Democracy\",\n    x = \"GDP per Capita\",\n    y = \"Libearl Democracy Index\"\n  ) +\n  guides(color = \"none\") +\n  scale_color_manual(values = c(\"#260b27\", \"darkorange\")) +\n  theme_bw()\n#+\n#  geom_text(aes(x = 0, y = 150), label = \"Positive residual\", color = \"#e6b0e7\", hjust = 0, size = 8) +\n # geom_text(aes(x = 150, y = 25), label = \"Negative residual\", color = \"#260b27\", hjust = 0, size = 8)\n\n```\n\n## Very Simple Example\n\nWhat should the slope and intercept be?\n\n```{r}\n#| label: best-line4\n\n# create data\ndat <- tibble(\n    x = c(1, 2, 3),\n    y = c(1, 2, 3)\n)\n\nggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(0,4) +\n  theme_bw()\n```\n\n\n## Example\n\n$\\hat{Y} = 0 + 1*X$\n\n```{r}\n#| label: best-line5\n\n# create data\nggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(0,4) +\n  geom_segment(x=0, y=0, xend=4, yend=4, color=\"darkorange\") +\n  theme_bw()\n```\n\n## Example\n\nWhat is the sum of squared residuals?\n\n```{r}\n#| label: best-line6\n\n# create data\nggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(0,4) +\n  geom_segment(x=0, y=0, xend=4, yend=4, color=\"darkorange\") +\n  theme_bw()\n```\n\n## Example\n\nWhat is sum of squared residuals for $y = 0 + 0*X$?\n\n```{r}\n#| label: best-line7\n\n# create data\n ggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(0,4) +\n  geom_segment(x=0, y=0, xend=4, yend=0, color=\"black\") +\n  theme_bw()\n```\n\n\n## Example\n\nWhat is sum of squared residuals for $y = 0 + 0*X$?\n\n```{r}\n#| label: best-line8\n\n# create data\n ggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(0,4) +\n  geom_segment(x=0, y=0, xend=4, yend=0, color=\"black\") +\n  theme_bw()\n```\n\n\n```{r}\n#| label: best-line9\n#| echo: true\n\n(1-0)^2 + (2-0)^2 + (3-0)^2\n```\n\n## Example\n\nWhat is sum of squared residuals for $y = 0 + 2*X$?\n\n```{r}\n#| label: best-line10\n\n# create data\n ggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(0,8) +\n  geom_segment(x=0, y=0, xend=4, yend=8, color=\"black\") +\n  theme_bw()\n```\n\n## Example\n\nWhat is sum of squared residuals for $y = 0 + 2*X$?\n\n```{r}\n#| label: best-line11\n\n ggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(0,8) +\n  geom_segment(x=0, y=0, xend=4, yend=8, color=\"black\") +\n  theme_bw()\n```\n\n\n```{r}\n#| label: best-line12\n#| echo: true\n\n(1-2)^2 + (2-4)^2 + (3-6)^2\n```\n\n\n## One more...\n\nWhat is sum of squared residuals for $y = 0 + -1*X$?\n\n```{r}\n#| label: best-line13\n\n ggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(-4,4) +\n  geom_segment(x=0, y=0, xend=4, yend=-4, color=\"black\") +\n  theme_bw()\n```\n\n## One more...\n\nWhat is sum of squared residuals for $y = 0 + -1*X$?\n\n```{r}\n#| label: best-line14\n\n ggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(-4,4) +\n  geom_segment(x=0, y=0, xend=4, yend=-4, color=\"black\") +\n  theme_bw()\n```\n\n\n```{r}\n#| label: best-line15\n#| echo: true\n\n(1+1)^2 + (2+2)^2 + (3+3)^2\n```\n\n## Cost Function\n\nSum of Squared Residuals as function of possible values of $b$\n\n\n```{r}\n#| label: cost-function\n\nsse <- tibble(\n          b=c(-2, -1, 0, 1, 2, 3, 4), \n          c=c(81, 56, 14, 0, 14, 56, 81)\n          )\n\nggplot(sse, aes(y=c, x=b)) +\n    geom_point(size=3, color=\"darkred\") +\n    labs(\n    x = \"Slope (b)\",\n    y = \"Sum of Squared Residuals\"\n  ) +\n  theme_bw()\n```\n\n\n## Least Squares Regression\n\n<br>\n\n- When we estimate a least squares regression, it is looking for the line that minimizes sum of squared residuals\n\n- In the simple example, I set $a=0$ to make it easier.  More complicated when searching for combination of $a$ and $b$ that minimize, but same basic idea\n\n## Least Squares Regression\n\n<br>\n\n- There is a way to solve for this analytically for linear regression (i.e., by doing math...)\n\n    -- They made us do this in grad school...\n\n. . .\n\n- In machine learning, people also use gradient descent algorithm in which the computer searches over possible combinations of $a$ and $b$ until it settles on the lowest point.    \n\n## Least Squares Regression\n\n```{r}\n#| label: ssr-viz\n\nsse <- tibble(\n          b=c(-2, -1, 0, 1, 2, 3, 4), \n          c=c(81, 56, 14, 0, 14, 56, 81)\n          )\n\nggplot(sse, aes(y=c, x=b)) +\n    geom_point(size=3, color=\"darkred\") +\n  #  geom_line(color = \"darkred\") +\n    labs(\n    x = \"Slope (b)\",\n    y = \"Sum of Squared Residuals\"\n  ) +\n  theme_bw()\n```\n\n## Least Squares Regression\n\n```{r}\n#| label: regression-line\n\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GDP per capita\", y = \"Liberal Democracy Index\") +\n  theme(\n    axis.text  = element_blank(),\n    axis.ticks = element_blank()\n    ) +\n  theme_bw()\n```\n\n## Your Turn {.smaller}\n\n<br>\n\nAre democracies less corrupt?\n\n<br>\n\n- V-Dem includes a Political Corruption Index, which aggregates corruption in a number of spheres (see codebook for details).  \n\n- The variable name is: *v2x_corr* : lower values mean less corruption\n\n- See started code [HERE](https://www.dropbox.com/scl/fo/8xpsrz27m0on1mc2pf5ya/h?rlkey=716y4lvy6uisq0gortq1as0sp&dl=0)\n\n\n## Your Turn {.smaller}\n\n<br>\n\n**Are democracies less corrupt?**\n\n<br>\n\n::: {.smaller}\n- Filter the V-Dem data to only include the year 2019\n- Make a scatterplot to visualize the relationship between democracy (X) and corruption (Y) (use the *v2x_libdem* variable for democracy)\n- Fit a linear model\n- Interpret results for the slope and intercept\n- For a country with the average (mean) level of democracy, what is the predicted level of corruption?\n:::\n\n```{r}\n#| label: time1\n\nlibrary(countdown)\n\ncountdown(minutes = 10, \n          id = \"timer1\", \n          bottom = \"5%\", \n          right = \"10%\",\n          color_border = \"#fff\",\n          color_text = \"#fff\",\n          color_running_background = \"#42affa\",\n          color_running_text = \"black\",\n          color_finished_background = \"#E5D19D\",\n          color_finished_text = \"#00264A\")\n```\n\n## Create Your Own Model {.smaller}\n\n<br>\n\n- What is a theory that you would like to test with V-Dem data?\n- What is the dependent variable? \n- What is the independent variable? \n- Map out steps to wrangle the data and fit a regression model\n- What do you expect to find? \n- Now go ahead and wrangle the data\n- Fit the model\n- Interpret the coefficients and their significance\n- Did the results match your expectations?\n\n","srcMarkdownNoYaml":"\n\n\n```{r} \n#| label: packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(vdemdata)\n\nset.seed(1234)\n```\n\n## Modeling \n\n::: {.incremental}\n- Use models to explain the relationship between variables and to make predictions\n- Explaining relationships [usually interested in causal relationships, but not always]\n    - Does oil wealth impact regime type?\n- Predictive modeling\n    - Where is violence most likely to happen in [country X] during their next election?\n    - Is this email spam?\n:::\n    \n## Modeling\n\n```{r}\n#| label: linear-model\n\ndf1 <- tibble(x = 1:100, y = x + rnorm(100, mean = 0, sd = 5))\n\nggplot(df1, aes(x = x, y = y)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(title = \"Linear\", x = NULL, y = NULL) +\n  theme_bw()\n```\n\n## Modeling\n\n```{r}\n#| label: nonlinear-model\n\ndf2 <- tibble(x = seq(-6, 5.9, 0.1), y = (1 / (1+exp(-2*x))) + rnorm(120, mean = 0, sd = 0.1))\n\nggplot(df2, aes(x = x, y = y)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", color = \"#8E2C90\", se = FALSE) +\n  labs(title = \"Non-linear\", x = NULL, y = NULL) +\n  theme_bw()\n```\n\n# Example: GDP per capita and Democracy\n\n## Pull in the VDEM Data\n\n<br>\n\nWhat is this code doing?\n\n```{r}\n#| label: wrangle-vdem\n#| echo: true\n\nlibrary(vdemdata)\n\nmodelData <- vdem |>\n  filter(year == 2019) |> \n  select(\n    country = country_name, \n    lib_dem = v2x_libdem, \n    wealth = e_gdppc) |>\n  mutate(log_wealth = log(wealth))\n\nglimpse(modelData)\n```\n\n## Plot the Relationship\n\n```{r}\n#| label: plot-wealth-dem-1\n\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n#  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(\n    title = \"Wealth and Democracy, 2019\",\n    x = \"GPD per capita\", \n    y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n## Plot the Relationship\n\n```{r}\n#| label: plot-wealth-dem-2\n\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(\n    title = \"Wealth and Democracy, 2019\",\n    x = \"GPD per capita\", \n    y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n## Plot the Relationship\n\n<br>\n\n```{r}\n#| label: plot-wealth-dem-3\n#| echo: true\n#| eval: false\n\nggplot(modelData, aes(x = wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GPD per capita\", y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n## Using the Scales Package\n\n\n```{r}\n#| label: plot-wealth-dem-4\n\nggplot(modelData, aes(x = wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  scale_x_log10(label = scales::label_dollar(suffix = \"k\")) +\n  labs(\n    title = \"Wealth and Democracy, 2019\",\n    x = \"GPD per capita\", \n    y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n## Using the Scales Package\n\n<br>\n\n```{r}\n#| label: plot-wealth-dem-5\n#| code-line-numbers: \"1,4\"\n#| echo: true\n#| eval: false\n\nggplot(modelData, aes(x = wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  scale_x_log10(label = scales::label_dollar(suffix = \"k\")) +\n  labs(\n    title = \"Wealth and Democracy, 2019\",\n    x = \"GPD per capita\", \n    y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n## Models as Functions\n\n::: {.incremental}\n- We can represent relationships between variables using **functions**\n- A function is a mathematical concept: the relationship between an output and one or more inputs\n  - Plug in the inputs and receive back the output\n- Example: The formula $y = 3x + 7$ is a function with input $x$ and output $y$. \n    - If $x$ is $5$, $y$ is $22$, \n    - $y = 3 \\times 5 + 7 = 22$\n:::\n\n## Quant Lingo {.smaller}\n\n<br>\n\n::: {.incremental}\n- **Response variable:** Variable whose behavior or variation you are trying to understand, on the y-axis in the plot\n    - **Dependent** variable\n    - **Outcome** variable\n    - **Y** variable\n- **Explanatory variables:** Other variables that you want to use to explain the variation in the response, on the x-axis in the plot\n    - **Independent** variables\n    - **Predictors**\n:::\n\n## \n\n<br>\n\nLinear model with one explanatory variable...\n\n::: {.incremental}\n- $Y = a + bX$\n- $Y$ is the outcome variable\n- $X$ is the explanatory variable\n- $a$ is the intercept: the predicted value of $Y$ when $X$ is equal to 0\n- $b$ is the slope of the line [remember rise over run!]\n:::\n\n## Quant Lingo {.smaller}\n\n<br>\n\n::: {.incremental}\n- **Predicted value:** Output of the **model function**\n   - The model function gives the typical (expected) value of the response variable *conditioning* on the explanatory variables\n   - We often call this $\\hat{Y}$ to differentiate the predicted value from an observed value of Y in the data\n- **Residuals:** A measure of how far each case is from its predicted value (based on a particular model)\n  - Residual = Observed value ($Y$) - Predicted value ($\\hat{Y}$)\n  - How far above/below the expected value each case is\n:::\n\n## Residuals\n\n```{r , echo = FALSE, warning = FALSE, out.width = \"60%\"}\n\nmod_fit <- linear_reg() |>\n  set_engine(\"lm\") |>\n  fit(lib_dem ~ log_wealth, data = modelData)\n\nfit_tidy <- tidy(mod_fit$fit) \nfit_aug  <- augment(mod_fit$fit) |>\n  mutate(res_cat = ifelse(.resid > 0, TRUE, FALSE))\n\na <- round(fit_tidy$estimate[1], 2)\nb <- round(fit_tidy$estimate[2], 2)\n\nggplot(data = fit_aug) +\n  geom_point(aes(x = log_wealth, y = lib_dem, color = res_cat)) +\n  geom_line(aes(x = log_wealth, y = .fitted), size = 0.75, color = \"#8E2C90\") + \n  labs(\n    title = \"GDP per Capita and Democracy\",\n    x = \"GDP per Capita\",\n    y = \"Libearl Democracy Index\"\n  ) +\n  guides(color = \"none\") +\n  scale_color_manual(values = c(\"#260b27\", \"darkorange\")) +\n  theme_bw()\n#+\n#  geom_text(aes(x = 0, y = 150), label = \"Positive residual\", color = \"#e6b0e7\", hjust = 0, size = 8) +\n # geom_text(aes(x = 150, y = 25), label = \"Negative residual\", color = \"#260b27\", hjust = 0, size = 8)\n\n```\n\n## Linear Model\n\n$\\hat{Y} = a  + b \\times X$\n\n$\\hat{Y} = `r a`  + `r b` \\times X$\n\n```{r echo=FALSE, out.width = \"100%\"}\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GPD per capita\", y = \"Liberal Democracy Index\") +\n  theme_bw()\n#+\n # theme(\n  #  axis.text  = element_blank(),\n   # axis.ticks = element_blank()\n   # )\n```\n\n## Linear Model: Interpretation\n\n<br>\n\n| $\\hat{Y} = a  + b \\times X$\n| $\\hat{Y} = `r a`  + `r b` \\times X$\n\nWhat is the interpretation of our estimate of $a$?\n\n. . .\n\n<br>\n\n| $\\hat{Y} = `r a`  + `r b` \\times 0$\n| $\\hat{Y} = `r a`$\n\n$a$ is our predicted level of democracy when GDP per capita is 0.\n\n\n## Linear Model: Interpretation \n<br>\n\n\n| $\\hat{Y} = a  + b \\times X$\n| $\\hat{Y} = `r a`  + `r b` \\times X$\n\nWhat is interpretation of our estimate of $b$?\n\n. . . \n\n<br>\n\n| $\\hat{Y} = a  + \\frac{Rise}{Run} \\times X$\n| $\\hat{Y} = a  + \\frac{Change Y}{Change X} \\times X$\n\n## Linear Model: Interpretation {.smaller}\n\n<br>\n\n| $b = \\frac{Change Y}{Change X}$\n| $`r b` = \\frac{Change Y}{Change X}$\n| ${Change Y} = `r b` * {ChangeX}$\n\n. . .\n\n<br>\n\n| When $ChangeX = 1$:\n| ${Change Y = `r b`}$\n\n. . .\n\n<br>\n\n| $b$ is the predicted change in $Y$ **associated with** a ONE unit change in X.\n\n## Linear Model: Interpretation\n\n\n```{r echo=FALSE}\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GPD per capita\", y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n## Linear Model: Interpretation\n\n```{r echo=FALSE}\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GPD per capita\", y = \"Liberal Democracy Index\") +\n  geom_segment(aes(x = 2, xend= 3, y=.37, yend=.37), colour=\"darkblue\", linewidth=1.5, arrow = arrow(length = unit(0.5, \"cm\"))) +\n  theme_bw()\n  \n#Ŷ =0.13+0.12×X\n```\n\n## Linear Model: Interpretation\n\n```{r echo=FALSE}\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GPD per capita\", y = \"Liberal Democracy Index\") +\n  geom_segment(aes(x = 2, xend= 3, y=.37, yend=.37), colour=\"darkblue\", linewidth=1.5) +\n  geom_segment(aes(x = 3, xend= 3, y=.37, yend=.49), colour=\"darkblue\", linewidth=1.5, arrow = arrow(length = unit(0.5, \"cm\"))) +\n  geom_text(x=3.2, y=.43, label=\"0.12\", color=\"darkblue\", size=4) +\n  theme_bw()\n  \n#Ŷ =0.13+0.12×X\n```\n\n\n## Linear Model: Interpretation\n\n<br>\n\nIs this the **causal** effect of GDP per capita on liberal democracy?\n\n. . .\n\n<br>\n\nNo! It is only the association...\n\n. . .\n\n<br>\n\nTo identify causality we need other methods (beyond the scope of this course).\n\n## Your Task\n\n<br> \n\nAn economist is interested in the relationship between years of education and hourly wages.  They estimate a linear model with estimates of $a$ and $b$ as follows:\n\n<br>\n\n$\\hat{Y} = 9 + 1.60*{YrsEdu}$\n\n<br>\n\n| 1. Interpret $a$ and $b$\n| 2. What is the predicted hourly wage for those with 10 years of education?\n\n## Next step\n\n<br>\n\n- Linear model with one predictor: $Y = a + bX$\n- For any given data...\n- How do we figure out what the best values are for $a$ and $b$??\n\n# Estimation\n\n## Linear Model with Single Predictor\n\n<br>\n\nGoal: Estimate Democracy score ($\\hat{Y_{i}}$) of a country given level of GDP per capita ($X_{i}$).\n\n<br>\n\nOr: Estimate relationship between GDP per capita and democracy.\n\n## Linear Model with Single Predictor\n\n```{r}\n#| label: model-data\n\nmodelData <- vdem |> \n  filter(year == 2019) |> \n  select(\n    country = country_name, \n    lib_dem = v2x_libdem, \n    wealth = e_gdppc, \n    corruption = v2x_corr, \n    ) |>\n  mutate(log_wealth = log(wealth)) \n  \n\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GDP per capita\", y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n# Estimate Model using Tidymodels\n\n## \n\n<br>\n\nStep 1: Specify model\n\n<br>\n\n```{r}\n#| label: specify-model\n#| echo: true\n#| eval: false\n\nlinear_reg()\n```\n\n## \n\n<br>\n\nStep 2: Set model fitting *engine*\n\n<br>\n\n```{r}\n#| label: set-engine\n#| echo: true\n#| eval: false\n\nlinear_reg() |>\n  set_engine(\"lm\") # lm: linear model\n```\n\n## \n\n<br>\n\nStep 3: Fit model & estimate parameters\n\n<bt>\n\n... using **formula syntax**\n\n```{r}\n#| label: fit-model\n#| echo: true\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(lib_dem ~ log_wealth, data = modelData) \n```\n\n## \n\n<br>\n\nStep 4: Tidy things up...\n\n<br>\n\n$$\\widehat{Democracy}_{i} = 0.13 + 0.12 * {loggdppc}_{i}$$\n\n```{r}\n#| label: tidy-model\n#| echo: true\n\nlinear_reg() |>\n  set_engine(\"lm\") |>\n  fit(lib_dem ~ log_wealth, data = modelData) |>\n  tidy()\n```\n\n\n## Interpretation?\n\n<br>\n\n$$\\widehat{Democracy}_{i} = 0.13 + 0.12 * {loggdppc}_{i}$$\n\n## Question\n\n<br>\n\nHow do we get the \"best\" values for the slope and intercept?\n\n\n## How would you draw the \"best\" line?\n\n```{r}\n#| label: best-line\n\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n # geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GDP per capita\", y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n\n## How would you draw the \"best\" line?\n\n```{r}\n#| label: best-line2\n\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GDP per capita\", y = \"Liberal Democracy Index\") +\n  theme_bw()\n```\n\n## Least squares regression\n\n<br>\n\n- Remember the residual is the difference between the actual value and the predicted value\n\n. . .\n\n- The regression line minimizes the sum of squared residuals.\n\n## Least squares regression\n\n<br>\n\n- Residual for each point is:  $e_i = y_i - \\hat{y}_i$\n\n- Least squares regression line minimizes $\\sum_{i = 1}^n e_i^2$.\n\n. . .\n\n- Why do we square the residual?\n\n. . .\n\n- Why not take absolute value?\n\n    - Principle: larger penalty for residuals further away\n    - Math: makes the math easier and some nice properties (not our concern here...)\n\n## Least squares regression\n\n\n```{r}\n#| label: best-line3 \n\nmod_fit <- linear_reg() %>%\n  set_engine(\"lm\") %>%\n  fit(lib_dem ~ log_wealth, data = modelData)\n\nfit_tidy <- tidy(mod_fit$fit) \nfit_aug  <- augment(mod_fit$fit) %>%\n  mutate(res_cat = ifelse(.resid > 0, TRUE, FALSE))\n\na <- round(fit_tidy$estimate[1], 2)\nb <- round(fit_tidy$estimate[2], 2)\n\nggplot(data = fit_aug) +\n  geom_point(aes(x = log_wealth, y = lib_dem, color = res_cat)) +\n  geom_line(aes(x = log_wealth, y = .fitted), size = 0.75, color = \"#8E2C90\") + \n  labs(\n    title = \"GDP per Capita and Democracy\",\n    x = \"GDP per Capita\",\n    y = \"Libearl Democracy Index\"\n  ) +\n  guides(color = \"none\") +\n  scale_color_manual(values = c(\"#260b27\", \"darkorange\")) +\n  theme_bw()\n#+\n#  geom_text(aes(x = 0, y = 150), label = \"Positive residual\", color = \"#e6b0e7\", hjust = 0, size = 8) +\n # geom_text(aes(x = 150, y = 25), label = \"Negative residual\", color = \"#260b27\", hjust = 0, size = 8)\n\n```\n\n## Very Simple Example\n\nWhat should the slope and intercept be?\n\n```{r}\n#| label: best-line4\n\n# create data\ndat <- tibble(\n    x = c(1, 2, 3),\n    y = c(1, 2, 3)\n)\n\nggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(0,4) +\n  theme_bw()\n```\n\n\n## Example\n\n$\\hat{Y} = 0 + 1*X$\n\n```{r}\n#| label: best-line5\n\n# create data\nggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(0,4) +\n  geom_segment(x=0, y=0, xend=4, yend=4, color=\"darkorange\") +\n  theme_bw()\n```\n\n## Example\n\nWhat is the sum of squared residuals?\n\n```{r}\n#| label: best-line6\n\n# create data\nggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(0,4) +\n  geom_segment(x=0, y=0, xend=4, yend=4, color=\"darkorange\") +\n  theme_bw()\n```\n\n## Example\n\nWhat is sum of squared residuals for $y = 0 + 0*X$?\n\n```{r}\n#| label: best-line7\n\n# create data\n ggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(0,4) +\n  geom_segment(x=0, y=0, xend=4, yend=0, color=\"black\") +\n  theme_bw()\n```\n\n\n## Example\n\nWhat is sum of squared residuals for $y = 0 + 0*X$?\n\n```{r}\n#| label: best-line8\n\n# create data\n ggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(0,4) +\n  geom_segment(x=0, y=0, xend=4, yend=0, color=\"black\") +\n  theme_bw()\n```\n\n\n```{r}\n#| label: best-line9\n#| echo: true\n\n(1-0)^2 + (2-0)^2 + (3-0)^2\n```\n\n## Example\n\nWhat is sum of squared residuals for $y = 0 + 2*X$?\n\n```{r}\n#| label: best-line10\n\n# create data\n ggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(0,8) +\n  geom_segment(x=0, y=0, xend=4, yend=8, color=\"black\") +\n  theme_bw()\n```\n\n## Example\n\nWhat is sum of squared residuals for $y = 0 + 2*X$?\n\n```{r}\n#| label: best-line11\n\n ggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(0,8) +\n  geom_segment(x=0, y=0, xend=4, yend=8, color=\"black\") +\n  theme_bw()\n```\n\n\n```{r}\n#| label: best-line12\n#| echo: true\n\n(1-2)^2 + (2-4)^2 + (3-6)^2\n```\n\n\n## One more...\n\nWhat is sum of squared residuals for $y = 0 + -1*X$?\n\n```{r}\n#| label: best-line13\n\n ggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(-4,4) +\n  geom_segment(x=0, y=0, xend=4, yend=-4, color=\"black\") +\n  theme_bw()\n```\n\n## One more...\n\nWhat is sum of squared residuals for $y = 0 + -1*X$?\n\n```{r}\n#| label: best-line14\n\n ggplot(dat, aes(y=y, x=x)) +\n  geom_point(size=3, color=\"darkblue\") +\n  xlim(0, 4) + ylim(-4,4) +\n  geom_segment(x=0, y=0, xend=4, yend=-4, color=\"black\") +\n  theme_bw()\n```\n\n\n```{r}\n#| label: best-line15\n#| echo: true\n\n(1+1)^2 + (2+2)^2 + (3+3)^2\n```\n\n## Cost Function\n\nSum of Squared Residuals as function of possible values of $b$\n\n\n```{r}\n#| label: cost-function\n\nsse <- tibble(\n          b=c(-2, -1, 0, 1, 2, 3, 4), \n          c=c(81, 56, 14, 0, 14, 56, 81)\n          )\n\nggplot(sse, aes(y=c, x=b)) +\n    geom_point(size=3, color=\"darkred\") +\n    labs(\n    x = \"Slope (b)\",\n    y = \"Sum of Squared Residuals\"\n  ) +\n  theme_bw()\n```\n\n\n## Least Squares Regression\n\n<br>\n\n- When we estimate a least squares regression, it is looking for the line that minimizes sum of squared residuals\n\n- In the simple example, I set $a=0$ to make it easier.  More complicated when searching for combination of $a$ and $b$ that minimize, but same basic idea\n\n## Least Squares Regression\n\n<br>\n\n- There is a way to solve for this analytically for linear regression (i.e., by doing math...)\n\n    -- They made us do this in grad school...\n\n. . .\n\n- In machine learning, people also use gradient descent algorithm in which the computer searches over possible combinations of $a$ and $b$ until it settles on the lowest point.    \n\n## Least Squares Regression\n\n```{r}\n#| label: ssr-viz\n\nsse <- tibble(\n          b=c(-2, -1, 0, 1, 2, 3, 4), \n          c=c(81, 56, 14, 0, 14, 56, 81)\n          )\n\nggplot(sse, aes(y=c, x=b)) +\n    geom_point(size=3, color=\"darkred\") +\n  #  geom_line(color = \"darkred\") +\n    labs(\n    x = \"Slope (b)\",\n    y = \"Sum of Squared Residuals\"\n  ) +\n  theme_bw()\n```\n\n## Least Squares Regression\n\n```{r}\n#| label: regression-line\n\nggplot(modelData, aes(x = log_wealth, y = lib_dem)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", color = \"#E48957\", se = FALSE) +\n  labs(x = \"GDP per capita\", y = \"Liberal Democracy Index\") +\n  theme(\n    axis.text  = element_blank(),\n    axis.ticks = element_blank()\n    ) +\n  theme_bw()\n```\n\n## Your Turn {.smaller}\n\n<br>\n\nAre democracies less corrupt?\n\n<br>\n\n- V-Dem includes a Political Corruption Index, which aggregates corruption in a number of spheres (see codebook for details).  \n\n- The variable name is: *v2x_corr* : lower values mean less corruption\n\n- See started code [HERE](https://www.dropbox.com/scl/fo/8xpsrz27m0on1mc2pf5ya/h?rlkey=716y4lvy6uisq0gortq1as0sp&dl=0)\n\n\n## Your Turn {.smaller}\n\n<br>\n\n**Are democracies less corrupt?**\n\n<br>\n\n::: {.smaller}\n- Filter the V-Dem data to only include the year 2019\n- Make a scatterplot to visualize the relationship between democracy (X) and corruption (Y) (use the *v2x_libdem* variable for democracy)\n- Fit a linear model\n- Interpret results for the slope and intercept\n- For a country with the average (mean) level of democracy, what is the predicted level of corruption?\n:::\n\n```{r}\n#| label: time1\n\nlibrary(countdown)\n\ncountdown(minutes = 10, \n          id = \"timer1\", \n          bottom = \"5%\", \n          right = \"10%\",\n          color_border = \"#fff\",\n          color_text = \"#fff\",\n          color_running_background = \"#42affa\",\n          color_running_text = \"black\",\n          color_finished_background = \"#E5D19D\",\n          color_finished_text = \"#00264A\")\n```\n\n## Create Your Own Model {.smaller}\n\n<br>\n\n- What is a theory that you would like to test with V-Dem data?\n- What is the dependent variable? \n- What is the independent variable? \n- Map out steps to wrangle the data and fit a regression model\n- What do you expect to find? \n- Now go ahead and wrangle the data\n- Fit the model\n- Interpret the coefficients and their significance\n- Did the results match your expectations?\n\n"},"formats":{"revealjs":{"identifier":{"display-name":"RevealJS","target-format":"revealjs","base-format":"revealjs"},"execute":{"fig-width":10,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":"auto","echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","html-math-method":{"method":"mathjax","url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML-full"},"slide-level":2,"to":"revealjs","output-file":"week-5.1.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":false,"quarto-version":"1.4.533","auto-stretch":true,"editor":"source","title":"Linear Regression","date":"today","date-format":"long","footer":"[IAFF 6501 Website](https://quant4ia.rocks/)","logo":"images/iaff6501-logo.png","theme":["simple","custom.scss"],"transition":"fade","slideNumber":true,"chalkboard":true}}},"projectFormats":["html"]}