{
  "hash": "02e4d92927291b502d7e60d584abc567",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Confidence Intervals\ndate: today\ndate-format: long\nfooter: \"[IAFF 6501 Website](https://quant4ia.rocks/)\"\nlogo: images/iaff6501-logo.png\nformat:\n  revealjs:\n    theme: [simple, custom.scss]\n    transition: fade\n    slide-number: true\n    #multiplex: true\n    chalkboard: true\nexecute:\n  echo: false\n  message: false\n  warning: false\n  freeze: auto\n---\n\n\n## {.smaller}\n\nOn December 19, 2014, the front page of Spanish national newspaper El\nPaís read *\"Catalan public opinion swings toward 'no' for independence, says survey\"*.^[Alberto Cairo. [The truthful art: Data, charts, and maps for communication](http://www.thefunctionalart.com/p/the-truthful-art-book.html). New Riders, 2016.]\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](week-4.1_files/figure-revealjs/catalan-misleading-1.png){width=960}\n:::\n:::\n\n\n## {.smaller}\n\nThe probability of the tiny difference between the 'No' and 'Yes' being just due to random chance is very high.^[Alberto Cairo. [\"Uncertainty and Graphicacy\"](https://ec.europa.eu/eurostat/cros/powerfromstatistics/OR/PfS-OutlookReport-Cairo.pdf), 2017.]\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week-4.1_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n## Characterizing Uncertainty\n\n<br>\n\n- We know from previous section that even unbiased procedures do not get the \"right\" answer every time\n- We also know that our estimates might vary from sample to sample due to random chance\n- Therefore we want to report on our estimate and our level of uncertainty\n\n\n## Characterizing Uncertainty\n\n<br>\n\n- With M&Ms, we knew the population parameter\n- In real life, we do not!\n- We want to generate an estimate *and* characterize our uncertainty with a *range* of possible estimates\n    \n## Solution: Create a Confidence Interval\n\n<br>\n\n- A plausible range of values for the population parameter is a confidence interval.\n\n. . .\n\n- 95 percent confidence interval is standard\n    - We are 95% confident that the parameter value falls within the range given by the confidence interval\n\n## Ways to Estimate\n\n<br>\n\n- Take advantage of Central Limit Theorem to estimate using math\n- Use simulation, bootstrapping \n\n## With Math...\n\n$$CI = \\bar{x} \\pm Z \\left( \\frac{\\sigma}{\\sqrt{n}} \\right)$$\n\n- $\\bar{x}$ is the sample mean,\n- $Z$ is the Z-score corresponding to the desired level of confidence\n- $\\sigma$ is the population standard deviation, and \n- $n$ is the sample size\n\n## \n\n<br>\n\nThis part here represents the standard error: \n\n$$\\left( \\frac{\\sigma}{\\sqrt{n}} \\right)$$\n\n- Standard deviation of the sampling distribution\n- Characterizes the spread of the sampling distribution\n- The bigger this is the bigger the CIs are going to be\n\n## Central Limit Theorem\n\n$$CI = \\bar{x} \\pm Z \\left( \\frac{\\sigma}{\\sqrt{n}} \\right)$$\n\n- This way of doing things depends on the Central Limit Theorem\n- As sample size gets bigger, the spread of the sampling distribution gets narrower\n- The shape of the sampling distributions becomes more normally distributed\n\n## \n\n<br>\n\n$$CI = \\bar{x} \\pm Z \\left( \\frac{\\sigma}{\\sqrt{n}} \\right)$$\n\nThis is therefore a **parametric** method of calculating the CI. It depends on assumptions about the normality of the distribution.  \n\n## Bootstrapping\n\n<br>\n\n::: incremental\n- Pulling oneself up from their bootstraps ... \n- Use the data we have to estimate the sampling distribution\n- We call this the *bootstrap* distribution\n- This is a **nonparametric** method\n- It does not depend on assumptions about normality\n:::\n\n## Bootstrap Process {.smaller}\n\n<br>\n\n1. Take a bootstrap sample - a random sample taken **with replacement** from the original sample, of the **same size** as the original sample\n\n. . .\n\n2. Calculate the bootstrap statistic - a statistic such as mean, median, proportion, slope, etc. computed on the bootstrap samples\n\n. . .\n\n3. Repeat steps (1) and (2) many times to create a bootstrap distribution - a distribution of bootstrap statistics\n\n. . .\n\n4. Calculate the bounds of the XX% confidence interval as the middle XX% \nof the bootstrap distribution (usually 95 percent confidence interval)\n\n\n## Russia\n\n<br>\n\nWhat Proportion of Russians believe their country interfered in the 2016 presidential elections in the US?\n\n- Pew Research survey\n- 506 subjects\n- Data available in the `openintro` package\n\n## \n\n<br>\n\nFor this example, we will use data from the Open Intro package. Install that package before running this code chunk.\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"openintro\")\nlibrary(openintro)\n\nglimpse(russian_influence_on_us_election_2016)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 506\nColumns: 1\n$ influence_2016 <chr> \"Did not try\", \"Did not try\", \"Did not try\", \"Don't kno…\n```\n\n\n:::\n:::\n\n\n\n## \n\n<br>\n\nLet's use `mutate()` to recode the qualitative variable as a numeric one...\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrussiaData <- russian_influence_on_us_election_2016 |> \n  mutate(try_influence = ifelse(influence_2016 == \"Did try\", 1, 0))\n```\n:::\n\n\n##\n\n<br>\n\nNow let's calculate the mean and standard deviation of the `try_influence` variable... \n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrussiaData |>\n  summarize( \n          mean = mean(try_influence),\n          sd = sd(try_influence)\n  )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n   mean    sd\n  <dbl> <dbl>\n1 0.150 0.358\n```\n\n\n:::\n:::\n\n\n## \n\n<br>\n\nAnd finally let's draw a bar plot...\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(russiaData, aes(x = try_influence)) +\n  geom_bar(fill = \"steelblue\", width = .75) +\n  labs(\n    title = \"Did Russia try to influence the U.S. election?\",\n    x = \"0 = 'No', 1 = 'Yes'\",\n    y = \"Frequncy\"\n  ) +\n  theme_minimal()\n```\n:::\n\n\n## \n\n<br>\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week-4.1_files/figure-revealjs/unnamed-chunk-8-1.png){width=960}\n:::\n:::\n\n\n## Bootstrap with `tidymodels`\n\nInstall `tidymodels` before running this code chunk... \n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"tidymodels\")\nlibrary(tidymodels)\n\nset.seed(66)\nboot_df <- russiaData |>\n  # specify the variable of interest\n  specify(response = try_influence) |>\n  # generate 15000 bootstrap samples\n  generate(reps = 15000, type = \"bootstrap\") |>\n  # calculate the mean of each bootstrap sample\n  calculate(stat = \"mean\")\n\nglimpse(boot_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 15,000\nColumns: 2\n$ replicate <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ stat      <dbl> 0.1146245, 0.1442688, 0.1343874, 0.1877470, 0.1521739, 0.138…\n```\n\n\n:::\n:::\n\n\n## \n\n<br>\n\nCalculate the confidence interval. A 95% confidence interval is bounded by the middle 95% of the bootstrap distribution.\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboot_df |>\n  summarize(lower = quantile(stat, 0.025),\n            upper = quantile(stat, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  lower upper\n  <dbl> <dbl>\n1 0.119 0.182\n```\n\n\n:::\n:::\n\n\n## \n\n<br>\n\nCreate upper and lower bounds for visualization.\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# for using these values later\nlower_bound <- boot_df |> summarize(lower_bound = quantile(stat, 0.025)) |> pull() \nupper_bound <- boot_df |> summarize(upper_bound = quantile(stat, 0.975)) |> pull() \n```\n:::\n\n\n##\n\n<br>\n\nVisualize with a histogram\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = boot_df, mapping = aes(x = stat)) +\n  geom_histogram(binwidth =.01, fill = \"steelblue4\") +\n  geom_vline(xintercept = c(lower_bound, upper_bound), color = \"darkgrey\", size = 1, linetype = \"dashed\") +\n  labs(title = \"Bootstrap distribution of means\",\n       subtitle = \"and 95% confidence interval\",\n       x = \"Estimate\",\n       y = \"Frequency\") +\n  theme_bw()\n```\n:::\n\n\n## \n\n<br>\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](week-4.1_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n## Interpret the confidence interval {.smaller}\n\n<br>\n\nThe 95% confidence interval was calculated as (`lower_bound`, `upper_bound`). Which of the following is the correct interpretation of this interval?\n\n<br>\n\n**(a)** 95% of the time the percentage of Russian who believe that Russia interfered in the 2016 US elections is between `lower_bound` and `upper_bound`.\n\n**(b)** 95% of all Russians believe that the chance Russia interfered in the 2016 US elections is between `lower_bound` and `upper_bound`.\n\n**(c)** We are 95% confident that the proportion of Russians who believe that Russia interfered in the 2016 US election is between `lower_bound` and `upper_bound`.\n\n**(d)** We are 95% confident that the proportion of Russians who supported interfering in the 2016 US elections is between `lower_bound` and `upper_bound`.\n\n## Your Turn! {.smaller}\n\n<br>\n\n- Change the `reps` argument in the `generate()` function to 1000. What happens to the width of the confidence interval?\n- Change the `reps` argument in the `generate()` function to 5000. What happens to the width of the confidence interval?\n- Change the `reps` argument in the `generate()` function to 10000. What happens to the width of the confidence interval?\n- How does the width of the confidence interval change as the number of bootstrap samples increases?\n- How would you interpret this finding? \n\n## Bias vs Precision\n\n- A procedure is *unbiased* if it generates the \"right\" answer, on average\n- Precision refers to variability: procedures with less sampling variability will be more precise\n    - all else equal, a greater sample size will increase precision\n- When we increase the sample size (number of reps), we increase precision\n- As a result our confidence interval will be narrower\n\n## Why did we do these simulations?\n\n<br>\n\n- They provide a foundation for statistical inference and for characterizing *uncertainty* in our estimates\n- The best **research designs** will try to maximize or achieve good balance on bias vs precision\n\n\n\n\n\n",
    "supporting": [
      "week-4.1_files/figure-revealjs"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}